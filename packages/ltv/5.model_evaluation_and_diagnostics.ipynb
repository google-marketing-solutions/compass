{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IaSc1TJ3fyx"
      },
      "source": [
        "## Disclaimer and license\n",
        "Copyright 2021 Google LLC. This solution, including any related sample code or data, is made available on an “as is,” “as available,” and “with all faults” basis, solely for illustrative purposes, and without warranty or representation of any kind. This solution is experimental, unsupported and provided solely for your convenience. Your use of it is subject to your agreements with Google, as applicable, and may constitute a beta feature as defined under those agreements. To the extent that you make any data available to Google in connection with your use of the solution, you represent and warrant that you have all necessary and appropriate rights, consents and permissions to permit Google to use and process that data. By using any portion of this solution, you acknowledge, assume and accept all risks, known and unknown, associated with its usage, including with respect to your deployment of any portion of this solution in your systems, or usage in connection with your business, if at all.\n",
        "\n",
        "Copyright 2021 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxxXTC7i3rlf"
      },
      "source": [
        "# 5.Model Evaluation and Diagnostics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afS2AgAH3uiH"
      },
      "source": [
        "This notebook demonstrates the evaluation of a LTV regression model by using the\n",
        "[Regression Diagnostics](https://github.com/google/gps_building_blocks/blob/master/py/gps_building_blocks/ml/diagnostics/regression.py)\n",
        "module.\n",
        "\n",
        "This evaluation consists of:\n",
        "* Model performance with respect to a variety of metrics.\n",
        "* Plots to understand the model performance to design media experiments.\n",
        "* Model insights (the relationship between features and the prediction values) helping to generate new business insights.\n",
        "* Insights helping to diagnose the model to make sure it is reasonable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ag1Rhu93RxU"
      },
      "source": [
        "## Requirements\n",
        "The model and the testing dataset should be available in GCP BigQuery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw1I4yQ_32vj"
      },
      "source": [
        "## Install and import required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiYQxYEc3b2Z"
      },
      "outputs": [],
      "source": [
        "# Uncomment to install required python modules\n",
        "#!pip install -r requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78JIAhwm8E3R"
      },
      "outputs": [],
      "source": [
        "from gps_building_blocks.cloud.utils import bigquery as bigquery_utils\n",
        "from gps_building_blocks.ml.diagnostics import regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYoWaBBY3rGw"
      },
      "source": [
        "## Set parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujIclxLF8Kxj"
      },
      "outputs": [],
      "source": [
        "# GCP Project ID\n",
        "PROJECT_ID = 'project_id'\n",
        "\n",
        "# BigQuery dataset name containing the testing predictions dataset\n",
        "PREDICTION_DATASET = 'predictions_dataset'\n",
        "\n",
        "# BigQuery table name containing the testing predictions dataset\n",
        "PREDICTION_TABLE = 'predictions_table'\n",
        "\n",
        "# Name of the column in the prediction table with the predicted label\n",
        "PREDICTED_LABEL = 'predicted_label'\n",
        "\n",
        "# Name of the column in the prediction table with the actual label\n",
        "ACTUAL_LABEL = 'actual_label'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpU-EH8W_Kgh"
      },
      "outputs": [],
      "source": [
        "bq_utils = bigquery_utils.BigQueryUtils(project_id=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPJI3_SB9HZh"
      },
      "source": [
        "## Read test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y18Q7O7_9L9I"
      },
      "source": [
        "In this step, we assume the test dataset containing both prediction and actual values is available in BigQuery."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tK-xt1x69GtB"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "  SELECT *\n",
        "  `{PROJECT_ID}.{PREDICTION_DATASET}.{PREDICTION_TABLE}`;\n",
        "\"\"\"\n",
        "\n",
        "df_pred_test = bq_utils.run_query(prediction_query).to_dataframe()\n",
        "df_pred_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i6623PC-iCf"
      },
      "source": [
        "## Run regression diagnostics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGMNCjNx_aM2"
      },
      "source": [
        "### Calculate performance metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73VJ8J9bBNz2"
      },
      "source": [
        "To check the regression model performance, we calculated the following metrics for diagnostic:\n",
        "- Mean squared error: a risk metric corresponding to the expected value of the squared error, calculated by taking the mean of squared error.\n",
        "- Root mean squared error: the root value of the mean squared error.\n",
        "- Mean absolute error: a risk metric corresponding to the expected of the absolute value, calculated by taking the mean of absolute error.\n",
        "- Mean absolute percentage error: an evaluation metric for regression problems, sensitive to relative errors, calculated by taking the mean of the absolute percentage error.\n",
        "- R-squared: coefficient of determination, representing the proportion of variance that has been explained by the independent variables in the model.\n",
        "- Pearson correlation: a correlation metric between actual and predicted labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LElmLQgD62i"
      },
      "outputs": [],
      "source": [
        "perf_metrics = regression.calc_performance_metrics(\n",
        "    labels=df_pred_test[ACTUAL_LABEL].VALUES,\n",
        "    predictions=df_pred_test[PREDICTED_LABEL].values,\n",
        "    deciamal_points=4)\n",
        "\n",
        "print(perf_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzkiLPyL--eV"
      },
      "source": [
        "### Scatter Plots of prediction values and residuals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRGLMOCWlo1F"
      },
      "source": [
        "The following function plots:\n",
        "1. the scatter plot of actual values versus prediction values\n",
        "2. the scatter plot of residuals versus predicted values\n",
        "From the first plot, we can see how prediction values differ from actual values, whether there exists strong correlation between the predictions and actual results. In the second plot, the residual plot, we can see how the residuals deviate from the line at zero since the residual equals to the actual value minus the prediction value. Ideal residual plots would be symmetrically distributed and cluster close to y=0 value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yeG6W1IHHsp"
      },
      "outputs": [],
      "source": [
        "regression.plot_prediction_residuals(\n",
        "    labels=df_pred_test[ACTUAL_LABEL].VALUES,\n",
        "    predictions=df_pred_test[PREDICTED_LABEL].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF4L8pWWAZUR"
      },
      "source": [
        "### Calculate performance metrics for the bins of the prediction values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8USUxFvRrrGN"
      },
      "source": [
        "The following function calculates performance metrics for each bin of the predictions. The default number of the bins of the prediction values is a parameter and here we use 10 as an example. The calculation is firstly rankd the prediction values from the highest to the lowest and then devide the predictions into 10 bins such that the first bin contains the highest 10% of the predictions and the second bin contains the next 10% of the predictions and so on. The following metrics are calculated for each bin:\n",
        "- mean_label: Mean of actual values in the bin.\n",
        "- mean_prediction: Mean of predictions in the bin.\n",
        "- rmse: Root mean squared error.\n",
        "- mape: Mean absolute percentage error.\n",
        "- corr: Pearson correlation coefficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z6xfBSpp29B"
      },
      "outputs": [],
      "source": [
        "bin_metrics = regression.calc_reg_bin_metrics(\n",
        "    labels=df_pred_test[ACTUAL_LABEL].VALUES,\n",
        "    predictions=df_pred_test[PREDICTED_LABEL].values,\n",
        "    number_bins=10)\n",
        "\n",
        "bin_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrmsaPP_qwgN"
      },
      "source": [
        "### Plot performance metrics for the bins of the prediction values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRX2klH9En2r"
      },
      "source": [
        "The following function plots performance metrics in each bin using bin_metrics calculated in last section. These plots allow us to have better understanding of predictions in the test dataset. In the first subplot, it shows the mean of actual and prediction values in each bin. An ideal plot would be the height of bars of both prediction and actual values decrease as the number of the bin increases. In the rest three plots (MAPE, RMSE, corr), the evaluation metric has same interpretation as in the regression models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTI_WfClrECG"
      },
      "outputs": [],
      "source": [
        "regression.plot_reg_bin_metrics(\n",
        "    bin_metrics=bin_metrics,\n",
        "    fig_width=25,\n",
        "    fig_height=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLevazIOAPGJ"
      },
      "source": [
        "### Plot actual distribution over the bins of the prediction values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwOiQ8nazTCy"
      },
      "outputs": [],
      "source": [
        "# TODO(): Add functions to plot actual distribution over the bins of the prediction values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h32ZIlNAiYp"
      },
      "source": [
        "### Confusion matrix of the actual vs predicted bins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGKgN-4La6Z0"
      },
      "outputs": [],
      "source": [
        "# TODO(): Add functions to calculate and plot confusion matrix."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "5.model_evaluation_and_diagnostics.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
