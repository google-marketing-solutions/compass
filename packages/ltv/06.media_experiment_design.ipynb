{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DNZzFa33WjvT",
      "metadata": {
        "id": "DNZzFa33WjvT"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RA_47EEJOY7E",
      "metadata": {
        "id": "RA_47EEJOY7E"
      },
      "source": [
        "# 6. Media experiment design"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ogxuFfmGL27U",
      "metadata": {
        "id": "ogxuFfmGL27U"
      },
      "source": [
        "This notebook demonstrates the design of a media experiment by using the\n",
        "[Experimental Design](https://github.com/google/gps_building_blocks/tree/master/py/gps_building_blocks/analysis/exp_design)\n",
        "module to activate the predictions from an LTV model. It is vital to design and estimate the impact of media campaigns using valid statistical methods to make sure the limited experimentation budget is utilized effectively and to set the right expectations of the campaign outcome.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F-53NJikOi25",
      "metadata": {
        "id": "F-53NJikOi25"
      },
      "source": [
        "### Requirements\n",
        "\n",
        "* An already scored test dataset, or the model and the test dataset to be scored available in GCP BigQuery.\n",
        "* This test dataset should contain all the ML instances for at least one snapshot date."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WEr7K1PtL1Xh",
      "metadata": {
        "id": "WEr7K1PtL1Xh"
      },
      "source": [
        "### Install and import required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BBatmzwvNous",
      "metadata": {
        "id": "BBatmzwvNous"
      },
      "outputs": [],
      "source": [
        "# Uncomment to install required python modules\n",
        "# !sh ../utils/setup.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "premium-optimization",
      "metadata": {
        "id": "premium-optimization"
      },
      "outputs": [],
      "source": [
        "# Add custom utils module to Python environment\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(os.path.abspath(os.pardir))\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from gps_building_blocks.analysis.exp_design import ab_testing_design\n",
        "from gps_building_blocks.cloud.utils import bigquery as bigquery_utils\n",
        "\n",
        "from utils import helpers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lbUSnFwRAsJo",
      "metadata": {
        "id": "lbUSnFwRAsJo"
      },
      "source": [
        "### Notebook custom settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ALNKImIIAxzS",
      "metadata": {
        "id": "ALNKImIIAxzS"
      },
      "outputs": [],
      "source": [
        "# Prints all the outputs from cell (instead of using display each time).\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = 'all'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BDX3PHZDUMXo",
      "metadata": {
        "id": "BDX3PHZDUMXo"
      },
      "source": [
        "### Set parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TDCwO7wjDbWI",
      "metadata": {
        "id": "TDCwO7wjDbWI"
      },
      "outputs": [],
      "source": [
        "configs = helpers.get_configs('config.yaml')\n",
        "dest_configs = configs.destination\n",
        "\n",
        "# GCP project ID\n",
        "PROJECT_ID = dest_configs.project_id\n",
        "# Name of the BigQuery dataset\n",
        "DATASET_NAME = dest_configs.dataset_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "incorrect-admission",
      "metadata": {
        "id": "incorrect-admission"
      },
      "outputs": [],
      "source": [
        "# To distinguish the separate runs of the training pipeline\n",
        "RUN_ID = '01'\n",
        "\n",
        "# BigQuery table name containing the test dataset to be scored. This test\n",
        "# dataset should contain all the instances at least for one snapshot date\n",
        "FEATURES_TEST_TABLE = f'features_test_table_{RUN_ID}'\n",
        "# Output BQML model name to save in BigQuery\n",
        "BQML_MODEL_NAME = f'ltv_model_bqml_{RUN_ID}'\n",
        "# BigQuery table name containing the scored test dataset\n",
        "FEATURES_TEST_PREDICTIONS_TABLE = f'predictions_table'\n",
        "# Selected snapshot date to select the ML instances (reflecting the instances to\n",
        "# be scored on a given scoring date) to be used for experiment design in\n",
        "# YYYY-MM-DD format\n",
        "SELECTED_SNAPSHOT_DATE = '2017-06-15'\n",
        "# Name of the actual label column\n",
        "ACTUAL_LABEL_NAME = 'label'\n",
        "# Name of the prediction column\n",
        "PREDICTED_LABEL_NAME = 'predicted_label'\n",
        "\n",
        "# BigQuery client object\n",
        "bq_utils = bigquery_utils.BigQueryUtils(project_id=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rwN9eDGxFzNE",
      "metadata": {
        "id": "rwN9eDGxFzNE"
      },
      "source": [
        "### Select the relevant data for experiment design\n",
        "Select all the instances for one snapshot date, which resembles the scoring dataset for one day. This dataset is used to design the media experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XH0C7e7yUsXo",
      "metadata": {
        "id": "XH0C7e7yUsXo"
      },
      "source": [
        "### Score the test dataset (if not already scored)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "short-invasion",
      "metadata": {
        "id": "short-invasion"
      },
      "outputs": [],
      "source": [
        "# Prediction sql query\n",
        "prediction_query =f\"\"\"\n",
        "  SELECT *\n",
        "  FROM ML.PREDICT(MODEL `{PROJECT_ID}.{DATASET_NAME}.{BQML_MODEL_NAME}`,\n",
        "                  TABLE `{PROJECT_ID}.{DATASET_NAME}.{FEATURES_TEST_TABLE}`)\n",
        "                  WHERE snapshot_ts='{SELECTED_SNAPSHOT_DATE}';\n",
        "\"\"\"\n",
        "\n",
        "# Run prediction\n",
        "print(prediction_query)\n",
        "df_test_predictions = bq_utils.run_query(prediction_query).to_dataframe()\n",
        "\n",
        "# Size of the prediction data frame\n",
        "print(df_test_predictions.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HO4YCzOCc5yo",
      "metadata": {
        "id": "HO4YCzOCc5yo"
      },
      "source": [
        "### Read the prediction test dataset (if already scored)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x7FUM0ZAc4bP",
      "metadata": {
        "id": "x7FUM0ZAc4bP"
      },
      "outputs": [],
      "source": [
        "# Data read in sql query\n",
        "read_query = f\"\"\"\n",
        "SELECT\n",
        "  {ACTUAL_LABEL_NAME},\n",
        "  {PREDICTED_LABEL_NAME},\n",
        "  snapshot_ts\n",
        "FROM\n",
        "  `{PROJECT_ID}.{DATASET_NAME}.{FEATURES_TEST_PREDICTIONS_TABLE}`\n",
        "WHERE\n",
        "  snapshot_ts = '{SELECTED_SNAPSHOT_DATE}';\n",
        "\"\"\"\n",
        "\n",
        "# Run prediction\n",
        "print(read_query)\n",
        "df_test_predictions = bq_utils.run_query(read_query).to_dataframe()\n",
        "\n",
        "# Size of the prediction data frame\n",
        "print(df_test_predictions.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d-7lf3PPF8UV",
      "metadata": {
        "id": "d-7lf3PPF8UV"
      },
      "source": [
        "### Experiment Design I: Different Remarketing LTV Groups\n",
        "\n",
        "One way to use the output from an LTV Model to optimize marketing is to first define different audience groups based on the predicted LTV value (such as High, Medium and Low LTV groups) and then test the same or different marketing strategies with those. This strategy is more useful to understand how different LTV groups respond to remarketing campaigns.\n",
        "\n",
        "Following step estimates the statistical sample sizes required for different groups (bins) of the predicted LTV based on different combinations of the expected minimum uplift/effect size, statistical power and statistical confidence levels specified as input parameters by using statistical T-test.\n",
        "\n",
        "Expected output: a Pandas Dataframe containing statistical sample size for each bin for each combination of minimum uplift_percentage, statistical power and statistical confidence level.\n",
        "\n",
        "Based on the estimated sample sizes and the available group sizes, one can decide what setting (expected minimum uplift/effect size at a given statistical power and a confidence level) to be selected for the experiment. Then the selected sample sizes could be used to set Test and Control cohorts from each LTV group to implement the media experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vHSFXVBFGanG",
      "metadata": {
        "id": "vHSFXVBFGanG"
      },
      "outputs": [],
      "source": [
        "ab_testing_design.calc_t_sample_sizes_for_bins(\n",
        "    labels=df_test_predictions[ACTUAL_LABEL_NAME].values,\n",
        "    numeric_predictions=df_test_predictions[PREDICTED_LABEL_NAME].values,\n",
        "    number_bins=3, # to have High, Medium and Low bins\n",
        "    uplift_percentages=(10, 15), # minimum expected effect sizes\n",
        "    power_percentages=(80, 90),\n",
        "    confidence_level_percentages=(90, 95))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ok5u6DJTHeQi",
      "metadata": {
        "id": "Ok5u6DJTHeQi"
      },
      "source": [
        "### Experiment Design II: Top LTV Group\n",
        "\n",
        "Another way to use the output from an LTV Model to optimize marketing is to target the top X% of users having the highest predicted LTV in a remarketing campaign, or an acquisition campaigns with the similar audience strategy.\n",
        "\n",
        "Following step estimates the statistical sample sizes required for different cumulative groups (bins) of the predicted LTV (top X%, top 2X% and so on) based on different combinations of the expected minimum uplift/effect size, statistical power and statistical confidence levels specified as input parameters by using statistical T-test.\n",
        "\n",
        "Expected output: a Pandas Dataframe containing statistical sample size for each cumulative bin for each combination of minimum uplift_percentage, statistical power and statistical confidence level.\n",
        "\n",
        "Based on the estimated sample sizes and the available group sizes one can decide what setting (what top X% of users with the expected minimum uplift/effect size at a given statistical power and a confidence level) to be selected for the experiment. Then the selected sample size could be used to set Test and Control cohorts from the top X% to implement the media experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sN4gT1OXHVfR",
      "metadata": {
        "id": "sN4gT1OXHVfR"
      },
      "outputs": [],
      "source": [
        "ab_testing_design.calc_t_sample_sizes_for_cumulative_bins(\n",
        "    labels=df_test_predictions[ACTUAL_LABEL_NAME].values,\n",
        "    numeric_predictions=df_test_predictions[PREDICTED_LABEL_NAME].values,\n",
        "    number_bins=10, # top 10%, 20%, ..., 100%\n",
        "    uplift_percentages=(10, 15), # minimum expected effect sizes\n",
        "    power_percentages=(80, 90),\n",
        "    confidence_level_percentages=(90, 95))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "F-53NJikOi25",
        "rwN9eDGxFzNE",
        "XH0C7e7yUsXo",
        "HO4YCzOCc5yo"
      ],
      "name": "6.media_experiment_design.ipynb",
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m87",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
