{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sUhciY7PW-eI",
      "metadata": {
        "id": "sUhciY7PW-eI"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c67dc34e",
      "metadata": {
        "id": "c67dc34e"
      },
      "source": [
        "# 7. Batch Scoring Based on Pretrained Propensity Model\n",
        "\n",
        "This notebook demonstrates how to create a scoring dataset and use it to predict probabilities based on a pretrained propensity model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Im-CvHi8Pcqc",
      "metadata": {
        "id": "Im-CvHi8Pcqc"
      },
      "source": [
        "### Requirements\n",
        "\n",
        "This notebook requires to have pretrained model stored in BigQuery. This can be done using [4. Model training notebook](4.model_training.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "035bb7ca",
      "metadata": {
        "id": "035bb7ca"
      },
      "source": [
        "### Install and import required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RVURsCubdyiI",
      "metadata": {
        "id": "RVURsCubdyiI"
      },
      "outputs": [],
      "source": [
        "# Uncomment to install required python modules\n",
        "# !sh ../utils/setup.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa66e333",
      "metadata": {
        "id": "fa66e333"
      },
      "outputs": [],
      "source": [
        "# Add custom utils module to Python environment\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(os.path.abspath(os.pardir))\n",
        "\n",
        "from gps_building_blocks.ml.data_prep.ml_windowing_pipeline import ml_windowing_pipeline\n",
        "from gps_building_blocks.cloud.utils import bigquery as bigquery_utils\n",
        "\n",
        "from utils import model\n",
        "from utils import helpers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d2fe9b6",
      "metadata": {
        "id": "4d2fe9b6",
        "tags": []
      },
      "source": [
        "### Step 1. Run scoring dataset generation pipeline\n",
        "\n",
        "Following executes MLWP's [Running Prediction Pipeline](https://github.com/google/gps_building_blocks/tree/master/py/gps_building_blocks/ml/data_prep/ml_windowing_pipeline#running-prediction-pipeline) to generate dataset for scoring. For features, make sure to use the parameters used in the training ML dataset creation. For detailed params of `run_prediction_pipeline.py`, refer to [Step 4. Run Features Pipeline](https://github.com/google/gps_building_blocks/tree/master/py/gps_building_blocks/ml/data_prep/ml_windowing_pipeline#step-4-run-features-pipeline) of MLWP."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83781a79",
      "metadata": {
        "id": "83781a79"
      },
      "source": [
        "Before generating the scoring dataset, first configure following variables based on your GCP project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5lsrLLPKE0Jo",
      "metadata": {
        "id": "5lsrLLPKE0Jo"
      },
      "outputs": [],
      "source": [
        "configs = helpers.get_configs('config.yaml')\n",
        "source_configs, dest_configs, run_id_configs = \\\n",
        "    configs.source, configs.destination, configs.run_id\n",
        "\n",
        "# GCP project ID\n",
        "PROJECT_ID = dest_configs.project_id\n",
        "# Name of the BigQuery dataset\n",
        "DATASET_NAME = dest_configs.dataset_name\n",
        "# Bigquery table name containing the original data to create scoring dataset.\n",
        "# Example: 'bigquery-public-data.google_analytics_sample.ga_sessions_*' for\n",
        "# Google Merchandize Store GA360 dataset\n",
        "SOURCE_TABLE_PATH = (f'{source_configs.project_id}'\n",
        "                    f'.{source_configs.dataset_name}'\n",
        "                    f'.{source_configs.table_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ebfde2b",
      "metadata": {
        "id": "3ebfde2b"
      },
      "outputs": [],
      "source": [
        "# To distinguish the separate scoring runs\n",
        "RUN_ID = run_id_configs.score\n",
        "\n",
        "# Snapshot date to make predictions from\n",
        "SNAPSHOT_DATE = '2017-06-15'\n",
        "# Length of the lookback window in days.\n",
        "# This should be the same as in the training ML dataset creation step\n",
        "LOOKBACK_WINDOW_SIZE_IN_DAYS = 30\n",
        "# Days from lookback window ends in relation to the snapshot date.\n",
        "# This should be the same as in the training ML dataset creation step\n",
        "LOOKBACK_WINDOW_GAP_IN_DAYS = 1\n",
        "# Local dir for MWLP sql templates in case customized SQL was used to create\n",
        "# the training ML dataset\n",
        "LOCAL_TEMPLATE_DIR = f'{os.getcwd()}/templates'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90cdbed6",
      "metadata": {
        "id": "90cdbed6"
      },
      "outputs": [],
      "source": [
        "scoring_parameters = {\n",
        "  'run_id': RUN_ID,\n",
        "  'project_id': PROJECT_ID,\n",
        "  'dataset_id': DATASET_NAME,\n",
        "  'analytics_table': SOURCE_TABLE_PATH,\n",
        "  'snapshot_date': SNAPSHOT_DATE,\n",
        "  'lookback_window_size_in_days': LOOKBACK_WINDOW_SIZE_IN_DAYS,\n",
        "  'lookback_window_gap_in_days': LOOKBACK_WINDOW_GAP_IN_DAYS,\n",
        "  'templates_dir': LOCAL_TEMPLATE_DIR,\n",
        "  'sessions_sql': 'sessions_google_analytics.sql',\n",
        "  'features_sql': 'features_from_input.sql',\n",
        "  'sum_values': 'totals_visits;totals_pageviews',\n",
        "  'avg_values': 'totals_visits;totals_pageviews',\n",
        "  'min_values': 'totals_visits;totals_pageviews',\n",
        "  'max_values': 'totals_visits;totals_pageviews',\n",
        "  'count_values': 'trafficSource_medium:[cpm,cpc,referral,affiliate,organic]:[Other];device_isMobile:[false,true]:[Other]',\n",
        "  'latest_values': 'trafficSource_medium:[cpm,cpc,referral,affiliate,organic]:[Other];device_isMobile:[false,true]:[Other]',\n",
        "  'proportions_values': 'trafficSource_medium:[cpm,cpc,referral,affiliate,organic]:[Other];device_isMobile:[false,true]:[Other]',\n",
        "  'mode_values': 'trafficSource_medium:[cpm,cpc,referral,affiliate,organic]:[Other];device_isMobile:[false,true]:[Other]',\n",
        "}\n",
        "\n",
        "ml_windowing_pipeline.run_prediction_pipeline(scoring_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "320b1041",
      "metadata": {
        "id": "320b1041"
      },
      "source": [
        "### Step 2. Run batch scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a33fe85b",
      "metadata": {
        "id": "a33fe85b"
      },
      "outputs": [],
      "source": [
        "# Initialize BigQuery client\n",
        "bq_utils = bigquery_utils.BigQueryUtils(project_id=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "095cf2af",
      "metadata": {
        "id": "095cf2af"
      },
      "outputs": [],
      "source": [
        "# BigQuery table name containing the dataset to be scored\n",
        "SCORING_FEATURES_TABLE = f'features_{RUN_ID}'\n",
        "# BigQuery table name to store the predictions from scoring\n",
        "SCORING_PREDICTION_TABLE = f'scored_{RUN_ID}'\n",
        "# BigQuery model name\n",
        "MODEL_NAME =  f'propensity_model_{run_id_configs.train}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5efd43cb",
      "metadata": {
        "id": "5efd43cb"
      },
      "outputs": [],
      "source": [
        "# Extract pretrained model features. This helps to verify which features were\n",
        "# used to train the propensity model.\n",
        "sql = f\"\"\"\n",
        "  SELECT\n",
        "    input\n",
        "    FROM ML.FEATURE_INFO(MODEL `{PROJECT_ID}.{DATASET_NAME}.{MODEL_NAME}`);\n",
        "\"\"\"\n",
        "expected_features = bq_utils.run_query(sql).to_dataframe()\n",
        "expected_features = expected_features['input'].tolist()\n",
        "print(f'Model expects following input features: \\n {expected_features}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0906d822-c103-4b2b-ba30-3bcc92bfda30",
      "metadata": {
        "id": "0906d822-c103-4b2b-ba30-3bcc92bfda30"
      },
      "outputs": [],
      "source": [
        "# Run batch scoring\n",
        "\n",
        "scoring_query =f\"\"\"\n",
        "  CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_NAME}.{SCORING_PREDICTION_TABLE}`\n",
        "  AS (\n",
        "    SELECT *\n",
        "    FROM ML.PREDICT(MODEL `{PROJECT_ID}.{DATASET_NAME}.{MODEL_NAME}`,\n",
        "                    TABLE `{PROJECT_ID}.{DATASET_NAME}.{SCORING_FEATURES_TABLE}`)\n",
        "  );\n",
        "\"\"\"\n",
        "print(scoring_query)\n",
        "bq_utils.run_query(scoring_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f18db472-8c11-4c36-ac9d-6440ecd4de61",
      "metadata": {
        "id": "f18db472-8c11-4c36-ac9d-6440ecd4de61"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "7.batch_scoring.ipynb",
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m87",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
