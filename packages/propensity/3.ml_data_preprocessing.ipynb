{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxntJHpGGbWJ"
      },
      "outputs": [],
      "source": [
        "# Copyright 2021 Google LLC.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXzbVhHq1E00"
      },
      "source": [
        "#3. ML Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afjpo9711ZcN"
      },
      "source": [
        "This notebook demonstrates the preparation of an already created ML dataset for model development. It is vital to split machine learning datasets in such a way that the model performance can be tuned and fairly assessed. This notebook shows an example of dividing a dataset into `out-of-time TEST` dataset (including selected full snapshot/s) and `DEVELOPMENT` dataset (randomly splitting the rest of the snapshots into `TRAIN`,`VALIDATION` and `TEST`). Those names are designed to be directly used in the AUTOML [DATA_SPLIT_COL](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-automl#data_split_col)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL72VhdvwRlN"
      },
      "source": [
        "## Requirements\n",
        "1. Using [ML Windowing Pipeline (MLWP)](https://github.com/google/gps_building_blocks/tree/master/py/gps_building_blocks/ml/data_prep/ml_windowing_pipeline) to create features tables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K-akTYXwRlN"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nj1IEIOAs9O"
      },
      "outputs": [],
      "source": [
        "# !pip install gps_building_blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8YqU8DxwRlO"
      },
      "outputs": [],
      "source": [
        "import google.auth\n",
        "from google.cloud import bigquery\n",
        "from gps_building_blocks.cloud.utils import bigquery as bigquery_utils\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFqIBFNtwRlQ"
      },
      "source": [
        "### Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZu8bQGKwRlQ"
      },
      "outputs": [],
      "source": [
        "# Prints all the outputs from cell (instead of using display each time).\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dWnMP1jwRlS"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed-O0oJhwRlS"
      },
      "outputs": [],
      "source": [
        "# Project we are working in.\n",
        "PROJECT_ID = 'project-id'\n",
        "\n",
        "# Name of the BigQuery dataset with MLWP tables.\n",
        "DATASET = \"dataset\"\n",
        "\n",
        "# Initial mwlp tables.\n",
        "TABLE_FEATURES = 'features_01'\n",
        "\n",
        "# ML datasets\n",
        "# These 4 tables will be created in {DATASET_DESTINATION}\n",
        "TABLE_DS_SPLIT = 'ds_split'\n",
        "TABLE_DS_TRAINING_BALANCED = 'ds_training_balanced'\n",
        "TABLE_DS_TEST ='ds_test_table'\n",
        "TABLE_DS_DEV ='ds_dev_table'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIbKMokdwRlP"
      },
      "outputs": [],
      "source": [
        "# Initialize BigQuery client.\n",
        "bq_client = bigquery_utils.BigQueryUtils(project_id=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-uXsf90wRlS"
      },
      "source": [
        "## Check feature dataset.\n",
        "\n",
        "1. Determine the right splitting strategy.\n",
        "2. Verify the date to use as a cut-off for the `OUT-OF-TIME TEST` dataset based on the positive rate trends.\n",
        "3. Check imbalance in the dataset and decide on a balancing strategy.\n",
        "4. Consider additional filtering of training data based on snapshot dates.\n",
        "5. Consider selecting a subset of the columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWQooJIawRlV"
      },
      "outputs": [],
      "source": [
        "# Check list of columns to investigate what features are available,\n",
        "# and potentially selecting a subset of them.\n",
        "sql = f\"\"\"\n",
        "SELECT\n",
        " *\n",
        "FROM\n",
        "  `{DATASET}.{TABLE_FEATURES}`\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "print (sql)\n",
        "df_raw = bq_client.run_query(sql).to_dataframe()\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3GcO6qjwRlV"
      },
      "outputs": [],
      "source": [
        "df_raw.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu-NkJAiwRlW"
      },
      "source": [
        "### Check proportion of positive instances in the features table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o1aG6X7wRlW"
      },
      "outputs": [],
      "source": [
        "# Produce summary of labels (positive/negative).\n",
        "sql = f\"\"\"\n",
        "SELECT\n",
        "  EXTRACT(DATE FROM snapshot_ts) AS effective_date,\n",
        "  COUNT(*) AS total_records,\n",
        "  COUNTIF(label=TRUE) AS count_positive,\n",
        "  COUNTIF(label=FALSE) AS count_negative,\n",
        "  SAFE_DIVIDE(COUNTIF(label=TRUE),\n",
        "  COUNTIF(label=FALSE)) AS ratio_positive_to_negative\n",
        "FROM\n",
        "  `{DATASET}.{TABLE_FEATURES}`\n",
        "GROUP BY\n",
        "  1\n",
        "ORDER BY\n",
        "  1 DESC;\n",
        "\"\"\"\n",
        "print (sql)\n",
        "df_raw = bq_client.run_query(sql).to_dataframe()\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2nhE4LGwRlW"
      },
      "outputs": [],
      "source": [
        "df_features_check = df_raw.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sxXK-xBwRlX"
      },
      "outputs": [],
      "source": [
        "fig = px.line(df_features_check,\n",
        "              x='effective_date',\n",
        "              y='ratio_positive_to_negative',\n",
        "              hover_name='count_positive',\n",
        "              title='Positive instances',\n",
        "              height=800)\n",
        "fig.show()\n",
        "df_features_check.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1H4Pb0FwRlZ"
      },
      "source": [
        "## Create dataset with split on snapshot dates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnCfbYsXwRla"
      },
      "source": [
        "#### Get recent effective dates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cWZ659EwRla"
      },
      "outputs": [],
      "source": [
        "# TODO(): Change split method to use start_date and end_date.\n",
        "# Get last effective dates.\n",
        "n_last_dates = 3\n",
        "recent_dates = df_features_check['effective_date'].sort_values(\n",
        "    ascending=False).head(n_last_dates).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV7rkM6JwRla"
      },
      "outputs": [],
      "source": [
        "# Keep this if you want to use data driven values for last dates in the dataset.\n",
        "test_dates = [str(x) for x in recent_dates]\n",
        "\n",
        "# Define dates here if you want to overwrite with curated dates.\n",
        "# It is useful to keep looking at a date that was used when\n",
        "# evaluating original model so we can make sure all performs as expected.\n",
        "# test_dates = ('2021-05-15', '2021-05-09')\n",
        "if len(test_dates) == 1:\n",
        "  test_dates = f\"('{tuple(test_dates)[0]}')\"\n",
        "else:\n",
        "  test_dates = tuple(test_dates)\n",
        "test_dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cgefSttwRla"
      },
      "outputs": [],
      "source": [
        "# Create the dataset if it doesn't exist.\n",
        "# TODO(): Fix the dataset creation with bq_client(utils version).\n",
        "dataset = bqclient.create_dataset(PROJECT_ID + '.' + DATASET, exists_ok=True)\n",
        "print(f'https://console.cloud.google.com/bigquery?project={PROJECT_ID}\u0026p={PROJECT_ID}\u0026d={DATASET_DESTINATION}\u0026page=dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3DpzF22wRlb"
      },
      "source": [
        "### Create dataset with columns indicating allocation to TRAIN/VALIDATE/TEST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1yDeFH3wRlb"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "# Add additional columns to dataset to indicate which rows are in which part (train/validate/test).\n",
        "# Compliant with automl split conventions.\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.{TABLE_DS_SPLIT}` AS (\n",
        "WITH\n",
        "  ds_features_key AS (\n",
        "  SELECT\n",
        "    *,\n",
        "    FARM_FINGERPRINT(user_id) AS key,\n",
        "  FROM\n",
        "    `{PROJECT_ID}.{DATASET}.{TABLE_FEATURES}`)\n",
        "SELECT\n",
        "*,\n",
        "  CASE\n",
        "    WHEN EXTRACT(DATE FROM TIMESTAMP (snapshot_ts)) in {test_dates} THEN 'TEST'\n",
        "    WHEN EXTRACT(DATE FROM TIMESTAMP (snapshot_ts)) not in {test_dates} and MOD(ABS(key), 10) in (0,1,2,3,4,5,6,7) THEN 'TRAIN'\n",
        "    WHEN EXTRACT(DATE FROM TIMESTAMP (snapshot_ts)) not in {test_dates} and MOD(ABS(key), 10) in (8) THEN 'VALIDATE'\n",
        "    WHEN EXTRACT(DATE FROM TIMESTAMP (snapshot_ts)) not in {test_dates} and  MOD(ABS(key), 10) in (9) THEN 'TEST'\n",
        "END as data_split,\n",
        "FROM\n",
        "  ds_features_key\n",
        "  );\n",
        "\"\"\"\n",
        "print (sql)\n",
        "df_raw = bq_client.run_query(sql).to_dataframe()\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sSJTG2MwRlb"
      },
      "source": [
        "## Create TEST (OUT-OF-TIME) dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsyQnADTwRlb"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.{TABLE_DS_TEST}` AS (\n",
        "SELECT * FROM\n",
        "`{PROJECT_ID}.{DATASET}.{TABLE_DS_SPLIT}`\n",
        "WHERE EXTRACT(DATE FROM TIMESTAMP (snapshot_ts)) in {test_dates}\n",
        ");\n",
        "\"\"\"\n",
        "print (sql)\n",
        "df_raw = bq_client.run_query(sql).to_dataframe()\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOrZ-S6JVALA"
      },
      "source": [
        "## Create DEVELOPMENT (IN-TIME) dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47Qn4pwOVCMs"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.{TABLE_DS_DEV}` AS (\n",
        "SELECT * FROM\n",
        "`{PROJECT_ID}.{DATASET}.{TABLE_DS_SPLIT}`\n",
        "WHERE EXTRACT(DATE FROM TIMESTAMP (snapshot_ts)) not in {test_dates}\n",
        ");\n",
        "\"\"\"\n",
        "print (sql)\n",
        "df_raw = bq_client.run_query(sql).to_dataframe()\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYBsqmqIwRlc"
      },
      "source": [
        "## Optional: Create balanced Train dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlZH3gBJwRlc"
      },
      "source": [
        "This optional step could be used to balance the instances when the % of positive examples in a dataset is very small (for example, less than 1%). When balancing, we will only balance the TRAIN partition of the TABLE_DS_DEV and keep both the VALIDATE and TEST partitions in their original imbalance ratio reflecting the natural data distribution.\n",
        "\n",
        "Below SQL script keeps all positive instances and then randomly samples records with negative labels; balance_ratio is a parameter we set to control how many times larger is the number of negative instances comparing to the number of positive instances in the resulting dataset. For example, balance_ratio=99 would mean that for every positive instance, we are sampling 99 negative instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA5Zb93swRlc"
      },
      "outputs": [],
      "source": [
        "# TODO(): Change the way we parametrize the ratio and\n",
        "# test on different imbalance cases.\n",
        "balance_ratio = 99\n",
        "sql = f\"\"\"\n",
        "# Checks imbalance in features by grouping on train/test/validate dataset.\n",
        "# Automatically balances and downsamples dataset and create one for training.\n",
        "CREATE OR REPLACE TABLE\n",
        "  `{PROJECT_ID}.{DATASET}.{TABLE_DS_TRAINING_BALANCED}` AS (\n",
        "WITH\n",
        "  dataset AS (\n",
        "  SELECT\n",
        "    *\n",
        "  FROM\n",
        "    `{PROJECT_ID}.{DATASET}.{TABLE_DS_SPLIT}`\n",
        "  WHERE\n",
        "    data_split='TRAIN' ),\n",
        "  imbalance_stats AS (\n",
        "  SELECT\n",
        "    data_split,\n",
        "    COUNT(*) AS total_records,\n",
        "    COUNTIF(label=TRUE) AS count_positive,\n",
        "    COUNTIF(label=FALSE) AS count_negative,\n",
        "    FORMAT(\"%.5f\", COUNTIF(label=TRUE)/COUNTIF(label=FALSE)) AS ratio_positive_to_negative\n",
        "  FROM\n",
        "    dataset\n",
        "  GROUP BY\n",
        "    1\n",
        "  ORDER BY\n",
        "    1),\n",
        "  -- Add a random seed to the negative examples.\n",
        "  negatives AS (\n",
        "  SELECT\n",
        "    *,\n",
        "    RAND() AS rand_seed\n",
        "  FROM\n",
        "    dataset\n",
        "  WHERE\n",
        "    label = FALSE),\n",
        "  negative_sampled AS (\n",
        "  SELECT\n",
        "    * EXCEPT (rand_seed)\n",
        "  FROM\n",
        "    negatives\n",
        "  WHERE\n",
        "    -- Here we are sampling the negatives using designed proportion.\n",
        "    rand_seed \u003c= (\n",
        "    SELECT\n",
        "      CAST(ratio_positive_to_negative AS float64)\n",
        "    FROM\n",
        "      imbalance_stats)*{balance_ratio} )\n",
        "  -- Union all together.\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  negative_sampled\n",
        "UNION ALL\n",
        "  -- Add all positive examples.\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  dataset\n",
        "WHERE\n",
        "  label = TRUE AND data_split = 'TRAIN'\n",
        "  );\n",
        "\"\"\"\n",
        "print (sql)\n",
        "df_raw = bq_client.run_query(sql).to_dataframe()\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLBnrxtFwRlc"
      },
      "source": [
        "### Check label balance in the new traning balanced dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC9fsl4KwRlc"
      },
      "outputs": [],
      "source": [
        "# Produce summary of labels(positive/negative).\n",
        "sql = f\"\"\"\n",
        "SELECT\n",
        "  snapshot_ts,\n",
        "  COUNT(*) AS total_records,\n",
        "  COUNTIF(label=TRUE) AS count_positive,\n",
        "  COUNTIF(label=FALSE) AS count_negative,\n",
        "  FORMAT(\"%.7f\", SAFE_DIVIDE(COUNTIF(label=TRUE),COUNTIF(label=FALSE))) AS ratio_positive_to_negative,\n",
        "  FORMAT(\"%.7f\", SAFE_DIVIDE(COUNTIF(label=TRUE), COUNT(*))) AS ratio_positive\n",
        "FROM\n",
        "  `{DATASET}.{TABLE_DS_TRAINING_BALANCED}`\n",
        "GROUP BY\n",
        "  1\n",
        "ORDER BY\n",
        "  1 DESC;\n",
        "\"\"\"\n",
        "\n",
        "print (sql)\n",
        "df_raw = bq_client.run_query(sql).to_dataframe()\n",
        "df_raw.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//corp/gtech/ads/infrastructure/colab_utils/ds_runtime:ds_colab",
        "kind": "private"
      },
      "name": "3.ml_data_preprocessing.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/third_party/professional_services/solutions/compass/packages/propensity/3_ml_data_preprocessing.ipynb?workspaceId=szczecinski:dev_compass_ml_preprocessing::citc",
          "timestamp": 1630655505596
        },
        {
          "file_id": "/piper/depot/google3/third_party/professional_services/solutions/compass/packages/propensity/3_ml_data_preprocessing.ipynb?workspaceId=szczecinski:dev_compass_ml_preprocessing::citc",
          "timestamp": 1630591931954
        },
        {
          "file_id": "/piper/depot/google3/third_party/professional_services/solutions/compass/packages/propensity/3_ml_data_preprocessing.ipynb?workspaceId=szczecinski:dev_compass_ml_preprocessing::citc",
          "timestamp": 1630425498904
        },
        {
          "file_id": "1bG5YLs51NoiibKl1CPGybSej756rFdkQ",
          "timestamp": 1629087932840
        }
      ],
      "toc_visible": true
    },
    "environment": {
      "name": "common-cpu.m46",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m46"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
