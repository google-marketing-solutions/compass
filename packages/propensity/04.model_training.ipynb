{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YZbZUe5qWEw4",
      "metadata": {
        "id": "YZbZUe5qWEw4"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9672db4",
      "metadata": {
        "id": "e9672db4"
      },
      "source": [
        "# 4. Model Training\n",
        "\n",
        "This notebook demonstrates how to train a Propensity Model using BigQuery ML."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8sHi8SaGNeuf",
      "metadata": {
        "id": "8sHi8SaGNeuf",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Requirements\n",
        "\n",
        "* Input features used for training needs to be stored as a BigQuery table. This can be done using [2. ML Data Preparation Notebook](2.ml_data_preparation.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "362fd965",
      "metadata": {
        "id": "362fd965"
      },
      "source": [
        "### Install and import required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MiDLLEg9lgHK",
      "metadata": {
        "id": "MiDLLEg9lgHK"
      },
      "outputs": [],
      "source": [
        "# Uncomment to install required python modules\n",
        "# !sh ../utils/setup.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da3a13bf",
      "metadata": {
        "id": "da3a13bf"
      },
      "outputs": [],
      "source": [
        "# Add custom utils module to Python environment\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(os.path.abspath(os.pardir))\n",
        "\n",
        "from gps_building_blocks.cloud.utils import bigquery as bigquery_utils\n",
        "\n",
        "from utils import model\n",
        "from utils import helpers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "765e25e3",
      "metadata": {
        "id": "765e25e3"
      },
      "source": [
        "### Set paramaters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "meoCNckfCdz3",
      "metadata": {
        "id": "meoCNckfCdz3"
      },
      "outputs": [],
      "source": [
        "configs = helpers.get_configs('config.yaml')\n",
        "dest_configs, run_id_configs = configs.destination, configs.run_id\n",
        "\n",
        "# GCP project ID\n",
        "PROJECT_ID = dest_configs.project_id\n",
        "# Name of the BigQuery dataset\n",
        "DATASET_NAME = dest_configs.dataset_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35c78327",
      "metadata": {
        "id": "35c78327"
      },
      "outputs": [],
      "source": [
        "# To distinguish the separate runs of the training pipeline\n",
        "RUN_ID = run_id_configs.train\n",
        "\n",
        "# BigQuery table name containing model development dataset\n",
        "FEATURES_DEV_TABLE = f'features_dev_table_{RUN_ID}'\n",
        "\n",
        "# BigQuery table name containing model testing dataset\n",
        "FEATURES_TEST_TABLE = f'features_test_table_{RUN_ID}'\n",
        "\n",
        "# Output model name to save in BigQuery\n",
        "MODEL_NAME = f'propensity_model_{RUN_ID}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ielOVQ2y4p-h",
      "metadata": {
        "id": "ielOVQ2y4p-h"
      },
      "outputs": [],
      "source": [
        "bq_utils = bigquery_utils.BigQueryUtils(project_id=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad9be3cf",
      "metadata": {
        "id": "ad9be3cf"
      },
      "source": [
        "Next, let's configure modeling options."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a59bce41",
      "metadata": {
        "id": "a59bce41"
      },
      "source": [
        "### Model and features configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57218f72",
      "metadata": {
        "id": "57218f72"
      },
      "source": [
        "Model options can be configured in detail based on BigQuery ML specifications\n",
        "listed in [The CREATE MODEL statement](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create).\n",
        "\n",
        "**NOTE**: Propensity modeling supports only following four types of models available in BigQuery ML:\n",
        "- LOGISTIC_REG\n",
        "- [AUTOML_CLASSIFIER](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-automl)\n",
        "- [BOOSTED_TREE_CLASSIFIER](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree)\n",
        "- [DNN_CLASSIFIER](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-dnn-models)\n",
        "\n",
        "In order to use specific model options, you can add options to following configuration exactly same as listed in the [The CREATE MODEL statement](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create). For example, if you want to trian [AUTOML_CLASSIFIER](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-automl) with `BUDGET_HOURS=1`, you can specify it as:\n",
        "\n",
        "```python\n",
        "params = {\n",
        "  'model_type': 'AUTOML_CLASSIFIER',\n",
        "  'budget_hours': 1\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7b95af5-3ca1-470f-b1df-d4bb00cf3c13",
      "metadata": {
        "id": "c7b95af5-3ca1-470f-b1df-d4bb00cf3c13"
      },
      "outputs": [],
      "source": [
        "# Read in Features table schema to select feature names for model training\n",
        "sql = (\"SELECT column_name \"\n",
        "       f\"FROM `{PROJECT_ID}.{DATASET_NAME}`.INFORMATION_SCHEMA.COLUMNS \"\n",
        "       f\"WHERE table_name='{FEATURES_DEV_TABLE}';\")\n",
        "\n",
        "print(sql)\n",
        "features_schema = bq_utils.run_query(sql).to_dataframe()\n",
        "\n",
        "# Columns to remove from the feature list\n",
        "to_remove = ['window_start_ts', 'window_end_ts', 'snapshot_ts', 'user_id',\n",
        "             'label', 'key', 'data_split']\n",
        "\n",
        "# Selected features for model training\n",
        "training_features = [v for v in features_schema['column_name']\n",
        "                     if v not in to_remove]\n",
        "\n",
        "print('Number of training features:', len(training_features))\n",
        "print(training_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6032a85b",
      "metadata": {
        "id": "6032a85b"
      },
      "outputs": [],
      "source": [
        "# Set parameters for AUTOML_CLASSIFIER model\n",
        "\n",
        "FEATURE_COLUMNS = training_features\n",
        "TARGET_COLUMN = 'label'\n",
        "\n",
        "params = {\n",
        "  'model_path': f'{PROJECT_ID}.{DATASET_NAME}.{MODEL_NAME}',\n",
        "  'features_table_path': f'{PROJECT_ID}.{DATASET_NAME}.{FEATURES_DEV_TABLE}',\n",
        "  'feature_columns': FEATURE_COLUMNS,\n",
        "  'target_column': TARGET_COLUMN,\n",
        "  'MODEL_TYPE': 'AUTOML_CLASSIFIER',\n",
        "  'BUDGET_HOURS': 1.0,\n",
        "  # ENABLE_GLOBAL_EXPLAIN is not available for AUTOML:\n",
        "  # https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create#other_model_options\n",
        "  'ENABLE_GLOBAL_EXPLAIN': False,\n",
        "  # Enable data_split_col if you want to use custom data split.\n",
        "  # Details on AUTOML data split column:\n",
        "  # https://cloud.google.com/automl-tables/docs/prepare#split\n",
        "  # 'DATA_SPLIT_COL': 'data_split',\n",
        "  'OPTIMIZATION_OBJECTIVE': 'MAXIMIZE_AU_ROC'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5027644",
      "metadata": {
        "id": "e5027644"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "First, we initialize `PropensityModel` with config parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4ab40a7",
      "metadata": {
        "id": "d4ab40a7"
      },
      "outputs": [],
      "source": [
        "propensity_model = model.PropensityModel(bq_utils=bq_utils,\n",
        "                                         params=params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2f442f7",
      "metadata": {
        "id": "c2f442f7"
      },
      "source": [
        "Next cell triggers model training job in BigQuery which takes some time to finish depending on dataset size and model complexity. Set `verbose=True`, if you want to verify training query details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pRKRB9Y92G1W",
      "metadata": {
        "id": "pRKRB9Y92G1W"
      },
      "outputs": [],
      "source": [
        "propensity_model.train(verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "327e792a",
      "metadata": {
        "id": "327e792a"
      },
      "source": [
        "Following cell allows you to see detailed information about the input features used to train a model. It provides following columns:\n",
        "- input — The name of the column in the input training data.\n",
        "- min — The sample minimum. This column is NULL for non-numeric inputs.\n",
        "- max — The sample maximum. This column is NULL for non-numeric inputs.\n",
        "- mean — The average. This column is NULL for non-numeric inputs.\n",
        "- stddev — The standard deviation. This column is NULL for non-numeric inputs.\n",
        "- category_count — The number of categories. This column is NULL for non-categorical columns.\n",
        "- null_count — The number of NULLs.\n",
        "\n",
        "For more details refer to [help page](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-feature)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22ce390",
      "metadata": {
        "id": "f22ce390"
      },
      "outputs": [],
      "source": [
        "propensity_model.get_feature_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RtYNNE6WZ77-",
      "metadata": {
        "id": "RtYNNE6WZ77-"
      },
      "source": [
        "### Evaluate the model\n",
        "This section helps to do quick model evaluation to get following model metrics:\n",
        "\n",
        "*  recall\n",
        "*  accuracy\n",
        "*  f1_score\n",
        "*  log_loss\n",
        "*  roc_auc\n",
        "\n",
        "Two optional parameters can be specified for evaluation:\n",
        "\n",
        "* eval_table: BigQuery table containing evaluation dataset\n",
        "* threshold: Custom probability threshold to be used for evaluation (to binarize the predictions). Default value is 0.5.\n",
        "\n",
        "If neither of these options are specified, the model is evaluated using evaluation dataset split during training with default threshold of 0.5.\n",
        "\n",
        "**NOTE:** This evaluation provides basic model performance metrics. For thorough evaluation refer to [5. Model evaluation notebook](5.model_evaluation_and_diagnostics.ipynb) notebook.\n",
        "\n",
        "TODO(): Add sql code to calculate the proportion of positive examples in the evaluation dataset to be used as the *threshold*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hPPMWyEEayps",
      "metadata": {
        "id": "hPPMWyEEayps"
      },
      "outputs": [],
      "source": [
        "# Model performance on the model development dataset on which the final\n",
        "# model has been trained\n",
        "\n",
        "EVAL_TABLE_NAME = FEATURES_DEV_TABLE\n",
        "\n",
        "eval_params = {\n",
        "  'eval_table_path':  f'{PROJECT_ID}.{DATASET_NAME}.{EVAL_TABLE_NAME}',\n",
        "  'threshold': 0.5\n",
        "}\n",
        "propensity_model.evaluate(eval_params, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xjvXKxHcay2K",
      "metadata": {
        "id": "xjvXKxHcay2K"
      },
      "outputs": [],
      "source": [
        "# Model performance on the held out test dataset\n",
        "\n",
        "EVAL_TABLE_NAME = FEATURES_TEST_TABLE\n",
        "\n",
        "eval_params = {\n",
        "  'eval_table_path':  f'{PROJECT_ID}.{DATASET_NAME}.{EVAL_TABLE_NAME}',\n",
        "  'threshold': 0.5\n",
        "}\n",
        "propensity_model.evaluate(eval_params, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1493e96",
      "metadata": {
        "id": "d1493e96"
      },
      "source": [
        "## Next"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07df0f1a",
      "metadata": {
        "id": "07df0f1a"
      },
      "source": [
        "Use [5. Model evaluation notebook](5.model_evaluation_and_diagnostics.ipynb) to get detailed performance metrics of the model and decide of model actually solves the business problem."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//research/colab/notebook:notebook_backend_py3",
        "kind": "private"
      },
      "name": "4.model_training.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/third_party/professional_services/solutions/compass/packages/propensity/04.model_training.ipynb?workspaceId=szczecinski:CS-04model_training-2022-05-12_141349::citc",
          "timestamp": 1652422188488
        }
      ]
    },
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m87",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
