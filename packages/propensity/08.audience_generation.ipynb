{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87cd9c05",
      "metadata": {
        "id": "87cd9c05"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e563d2a",
      "metadata": {
        "id": "2e563d2a"
      },
      "source": [
        "This notebook demonstrates the generation of a propensity audience for a remarketing use case. It relies on the sample size calculations from the [6.media_experiment_design.ipynb](https://source.corp.google.com/piper///depot/google3/third_party/professional_services/solutions/compass/packages/propensity/6.media_experiment_design.ipynb) notebook to create the Test and Control audiences which are written to a new BigQuery table. This data can then be uploaded via [measurement protocol](https://developers.google.com/analytics/devguides/collection/protocol/v1) to GA and used for the activation with the Google Ads products as demonstrated in [9.audience_upload.ipynb notebook](google3/third_party/professional_services/solutions/compass/packages/propensity/9.audience_upload.ipynb) notebook.\n",
        "\n",
        "**Requirements:**\n",
        "\n",
        "\n",
        "* An already scored dataset from the [7.batch_scoring.ipynb](google3/third_party/professional_services/solutions/compass/packages/propensity/7.batch_scoring.ipynb) notebook: this is the model prediction dataset containing ML prediction for each `user_id` and `snapshot_ts`, from which we create the remarketing audience.\n",
        "* Statistical sample size calculations from the [6.media_experiment_design.ipynb](https://source.corp.google.com/piper///depot/google3/third_party/professional_services/solutions/compass/packages/propensity/6.media_experiment_design.ipynb) notebook for each propensity audience group."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89b380f5",
      "metadata": {
        "id": "89b380f5"
      },
      "source": [
        "## Install and import required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5c220df",
      "metadata": {
        "id": "f5c220df"
      },
      "outputs": [],
      "source": [
        "# Uncomment to install required python modules\n",
        "# !sh ../utils/setup.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2f61cbb",
      "metadata": {
        "id": "a2f61cbb"
      },
      "outputs": [],
      "source": [
        "# Add custom utils module to Python environment\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(os.path.abspath(os.pardir))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from gps_building_blocks.cloud.utils import bigquery as bigquery_utils\n",
        "\n",
        "from utils import helpers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51254ad9",
      "metadata": {
        "id": "51254ad9"
      },
      "source": [
        "## Set parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PU1T6ipaFQ38",
      "metadata": {
        "id": "PU1T6ipaFQ38"
      },
      "outputs": [],
      "source": [
        "configs = helpers.get_configs('config.yaml')\n",
        "dest_configs, run_id_configs = configs.destination, configs.run_id\n",
        "\n",
        "# GCP project ID\n",
        "PROJECT_ID = dest_configs.project_id\n",
        "# Name of BigQuery dataset,\n",
        "# destination for created tables for modelling and activation.\n",
        "DATASET_NAME = dest_configs.dataset_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89618c5c",
      "metadata": {
        "id": "89618c5c"
      },
      "outputs": [],
      "source": [
        "# To distinguish the seperate runs of the ML Windowing Pipeline\n",
        "RUN_ID = run_id_configs.score\n",
        "# BigQuery table name containing the predictions (e.g. generated by\n",
        "# 7.batch_scoring.ipynb notebook)\n",
        "PREDICTIONS_TABLE = f'scored_{RUN_ID}'\n",
        "# Snapshot date to select the ML instances to create the marketing audience in\n",
        "# YYYY-MM-DD format\n",
        "SELECTED_SNAPSHOT_DATE = '2017-06-15'\n",
        "# Name of the column in the predictions table with the predicted label values\n",
        "PREDICTED_LABEL_NAME = 'predicted_label_probs'\n",
        "# Label value for the positive class\n",
        "POSITIVE_CLASS_LABEL = True\n",
        "# Number of propensity audience groups to devide the scored users into\n",
        "# (e.g. 3 bins for High, Medium and Low propensity audience groups)\n",
        "AUDIENCE_GROUPS = 3\n",
        "# Minimum samples sizes to select as the Test and Control groups for each the\n",
        "# propensity audience groups based on the output of the\n",
        "# 6.media_experiment_design.ipynb notebook (following are some example numbers).\n",
        "MIN_SAMPLE_SIZES = [1000, 2000, 3000]\n",
        "# Name of the BigQuery table with exported audience\n",
        "AUDIENCE_EXPORT_TABLE = f'audience_export_{RUN_ID}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4180295a",
      "metadata": {
        "id": "4180295a"
      },
      "outputs": [],
      "source": [
        "bq_utils = bigquery_utils.BigQueryUtils(project_id=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c96833",
      "metadata": {
        "id": "e8c96833"
      },
      "source": [
        "### Read the prediction dataset\n",
        "\n",
        "In this step, we assume the prediction dataset is available as a BigQuery table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f802c4ea",
      "metadata": {
        "id": "f802c4ea"
      },
      "outputs": [],
      "source": [
        "# SQL for extracting prediction dataset when using BQML.\n",
        "sql = f\"\"\"\n",
        "  SELECT\n",
        "    user_id,\n",
        "    snapshot_ts,\n",
        "    days_since_latest_activity,\n",
        "    days_since_first_activity,\n",
        "    probs.label AS predicted_score_label,\n",
        "    probs.prob AS score\n",
        "  FROM\n",
        "    `{PROJECT_ID}.{DATASET_NAME}.{PREDICTIONS_TABLE}` AS predictions,\n",
        "    UNNEST({PREDICTED_LABEL_NAME}) AS probs\n",
        "  WHERE\n",
        "    probs.label={POSITIVE_CLASS_LABEL}\n",
        "    AND snapshot_ts='{SELECTED_SNAPSHOT_DATE}';\n",
        "\"\"\"\n",
        "print (sql)\n",
        "df_prediction = bq_utils.run_query(sql).to_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8f61dda",
      "metadata": {
        "id": "a8f61dda"
      },
      "outputs": [],
      "source": [
        "df_prediction.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OmptfkZeN-8k",
      "metadata": {
        "id": "OmptfkZeN-8k"
      },
      "source": [
        "If required, the users can be filtered by using days_since_latest_activity\n",
        "(tenure) and days_since_first_activity (recency) columns before creating the\n",
        "audience groups."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87be2f9c",
      "metadata": {
        "id": "87be2f9c"
      },
      "source": [
        "### Create audience groups\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ff1vBP0zNG6e",
      "metadata": {
        "id": "Ff1vBP0zNG6e"
      },
      "outputs": [],
      "source": [
        "# Separate the users into \u003cAUDIENCE_GROUPS\u003e number of audience groups\n",
        "df_prediction = df_prediction.sort_values(by='score',\n",
        "                                          ascending=False).reset_index()\n",
        "# To avoid duplicate edges of bins we use the index\n",
        "# as rank in the qcut function below\n",
        "df_prediction['audience_group'] = pd.qcut(df_prediction.index,\n",
        "                                          q=AUDIENCE_GROUPS, labels=False)\n",
        "# When AUDIENCE_GROUPS=3, audience_group column contains '0', '1' and '2' values\n",
        "# representing 'High', 'Medium' and 'Low' propensity groups respectively\n",
        "\n",
        "# Separate each audience group into Test and Control\n",
        "df_prediction['test_control'] = 'NA'\n",
        "for i in range(len(MIN_SAMPLE_SIZES)):\n",
        "  group = df_prediction[df_prediction['audience_group'] == i]\n",
        "  # Select Control set size based on the minimum sample size\n",
        "  control_user_ids = random.sample(list(group['user_id']), MIN_SAMPLE_SIZES[i])\n",
        "  remaining_user_ids = list(set(group.user_id) - set(control_user_ids))\n",
        "\n",
        "  # Select Test set based on the minimum sample size\n",
        "  test_user_ids = random.sample(remaining_user_ids, MIN_SAMPLE_SIZES[i])\n",
        "  # Alternatively, select Test set to include all the remaining users as below\n",
        "  # or a subset of users greater than MIN_SAMPLE_SIZES[i] depending on the\n",
        "  # available campaign budget\n",
        "  # test_user_ids = remaining_user_ids\n",
        "\n",
        "  df_prediction.loc[df_prediction['user_id'].isin(test_user_ids),\n",
        "                    'test_control'] = 'Test'\n",
        "  df_prediction.loc[df_prediction['user_id'].isin(control_user_ids),\n",
        "                    'test_control'] = 'Control'\n",
        "\n",
        "# Explore the created audience sizes and statistics of the predicted\n",
        "# probabilities. We should expect to see simillar statistics of probabilities\n",
        "# between each Test and Control pair\n",
        "df_prediction.groupby(['audience_group', 'test_control']).agg(\n",
        "    {'score':['count', 'min', 'mean', 'median', 'max']})\n",
        "\n",
        "# TODO(): Add box plots to visualize the values of Test and\n",
        "# Control groups"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YiEcE2Mzm2N_",
      "metadata": {
        "id": "YiEcE2Mzm2N_"
      },
      "source": [
        "### Write the audience data to a BigQuery table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JnJGGbDbNHAO",
      "metadata": {
        "id": "JnJGGbDbNHAO"
      },
      "outputs": [],
      "source": [
        "# Inspect table before uploading to BigQuery\n",
        "cols_to_load = ['user_id',\n",
        "                'snapshot_ts',\n",
        "                'days_since_latest_activity',\n",
        "                'days_since_first_activity',\n",
        "                'predicted_score_label',\n",
        "                'score',\n",
        "                'audience_group',\n",
        "                'test_control']\n",
        "df_audience = df_prediction[cols_to_load]\n",
        "df_audience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cda943c-4f77-4899-82f0-d33cb9ed7389",
      "metadata": {
        "id": "1cda943c-4f77-4899-82f0-d33cb9ed7389"
      },
      "outputs": [],
      "source": [
        "destination_table =f'{DATASET_NAME}.{AUDIENCE_EXPORT_TABLE}'\n",
        "df_audience.to_gbq(\n",
        "    destination_table=destination_table,\n",
        "    project_id=PROJECT_ID,\n",
        "    if_exists='replace')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eTBVEMl3Z4n8",
      "metadata": {
        "id": "eTBVEMl3Z4n8"
      },
      "source": [
        "### Check final audience uploaded to a BigQuery table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v31mC-TcZ68X",
      "metadata": {
        "id": "v31mC-TcZ68X"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "  SELECT\n",
        "    snapshot_ts,\n",
        "    audience_group,\n",
        "    test_control,\n",
        "    COUNT(*) as count\n",
        "  FROM\n",
        "      `{PROJECT_ID}.{destination_table}`\n",
        "  GROUP BY\n",
        "    1,2,3\n",
        "  ORDER BY\n",
        "    1,2,3;\n",
        "\"\"\"\n",
        "print (sql)\n",
        "df_check = bq_utils.run_query(sql).to_dataframe()\n",
        "df_check"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//corp/gtech/ads/infrastructure/colab_utils/ds_runtime:ds_colab",
        "kind": "private"
      },
      "name": "8.audience_generation.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/third_party/professional_services/solutions/compass/packages/propensity/8a.audience_generation.ipynb?workspaceId=szczecinski:dev_audience_generation::citc",
          "timestamp": 1632737106105
        },
        {
          "file_id": "/piper/depot/google3/third_party/professional_services/solutions/compass/packages/propensity/8a.audience_generation.ipynb?workspaceId=szczecinski:dev_audience_generation::citc",
          "timestamp": 1631631928007
        },
        {
          "file_id": "1Dh3leR4-p532CVEYY613FKWH9bBUsSlc",
          "timestamp": 1631630733022
        }
      ]
    },
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m87",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
