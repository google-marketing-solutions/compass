{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sUhciY7PW-eI",
      "metadata": {
        "id": "sUhciY7PW-eI"
      },
      "outputs": [],
      "source": [
        "# Copyright 2021 Google LLC.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c67dc34e",
      "metadata": {
        "id": "c67dc34e"
      },
      "source": [
        "# 7. Batch Scoring Based on Pretrained Propensity Model\n",
        "\n",
        "This notebook demonstrates how to create a scoring dataset and use it to predict probabilities based on a pretrained propensity model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Im-CvHi8Pcqc",
      "metadata": {
        "id": "Im-CvHi8Pcqc"
      },
      "source": [
        "## Requirements\n",
        "\n",
        "This notebook requires to have pretrained model stored in BigQuery. This can be done using [4. Model training notebook](4.model_training.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "035bb7ca",
      "metadata": {
        "id": "035bb7ca"
      },
      "source": [
        "## Install and import required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RVURsCubdyiI",
      "metadata": {
        "id": "RVURsCubdyiI"
      },
      "outputs": [],
      "source": [
        "# Install gps_building_blocks package if not installed\n",
        "# !pip install gps_building_blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa66e333",
      "metadata": {
        "id": "fa66e333"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from utils import model\n",
        "from gps_building_blocks.ml.data_prep.ml_windowing_pipeline import ml_windowing_pipeline\n",
        "from gps_building_blocks.cloud.utils import bigquery as bigquery_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d2fe9b6",
      "metadata": {
        "id": "4d2fe9b6"
      },
      "source": [
        "## Step 1. Run Scoring Dataset Generation Pipeline\n",
        "\n",
        "Following executes MLWP's [Running Prediction Pipeline](https://github.com/google/gps_building_blocks/tree/master/py/gps_building_blocks/ml/data_prep/ml_windowing_pipeline#running-prediction-pipeline) to generate dataset for scoring. For features, make sure to use the parameters used in the training ML dataset creation. For detailed params of `run_prediction_pipeline.py`, refer to [Step 4. Run Features Pipeline](https://github.com/google/gps_building_blocks/tree/master/py/gps_building_blocks/ml/data_prep/ml_windowing_pipeline#step-4-run-features-pipeline) of MLWP."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83781a79",
      "metadata": {
        "id": "83781a79"
      },
      "source": [
        "Before generating the scoring dataset, first configure following variables based on your GCP project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ebfde2b",
      "metadata": {
        "id": "3ebfde2b"
      },
      "outputs": [],
      "source": [
        "# GCP Project ID\n",
        "PROJECT_ID = 'project-id'\n",
        "# BigQuery dataset name\n",
        "DATASET_NAME = 'dataset'\n",
        "# Bigquery table name containing the original data to create scoring dataset.\n",
        "# Example: 'bigquery-public-data.google_analytics_sample.ga_sessions_*' for\n",
        "# Google Merchandize Store GA360 dataset\n",
        "DATA_TABLE_NAME = 'table'\n",
        "\n",
        "# To distinguish the seperate runs of the MWLP\n",
        "RUN_ID = '01_score'\n",
        "# Snapshot date to make predictions from\n",
        "SNAPSHOT_DATE = '2021-01-01'\n",
        "# Length of the lookback window in days.\n",
        "# This should be the same as in the training ML dataset creation step\n",
        "LOOKBACK_WINDOW_SIZE_IN_DAYS = 7\n",
        "# Days from lookback window ends in relation to the snapshot date.\n",
        "# This should be the same as in the training ML dataset creation step\n",
        "LOOKBACK_WINDOW_GAP_IN_DAYS = 0\n",
        "# Local dir for MWLP sql templates in case customized SQL was used to create\n",
        "# the training ML dataset\n",
        "LOCAL_TEMPLATE_DIR = f'{os.getcwd()}/templates'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90cdbed6",
      "metadata": {
        "id": "90cdbed6"
      },
      "outputs": [],
      "source": [
        "scoring_parameters = {\n",
        "  'run_id': RUN_ID,\n",
        "  'project_id': PROJECT_ID,\n",
        "  'dataset_id': DATASET_NAME,\n",
        "  'analytics_table': DATA_TABLE_NAME,\n",
        "  'snapshot_date': SNAPSHOT_DATE,\n",
        "  'lookback_window_size_in_days': LOOKBACK_WINDOW_SIZE_IN_DAYS,\n",
        "  'lookback_window_gap_in_days': LOOKBACK_WINDOW_GAP_IN_DAYS,\n",
        "  'templates_dir': LOCAL_TEMPLATE_DIR,\n",
        "  'sessions_sql': 'sessions_google_analytics.sql', # or sessions_firebase.sql\n",
        "  'features_sql': 'features_from_input.sql',\n",
        "  'sum_values': 'totals_visits;totals_pageviews',\n",
        "  'avg_values': 'totals_visits;totals_pageviews',\n",
        "  'min_values': 'totals_visits;totals_pageviews',\n",
        "  'max_values': 'totals_visits;totals_pageviews',\n",
        "  'count_values': 'trafficSource_medium:[cpm,cpc,referral,affiliate,organic]:[Other];device_isMobile:[false,true]:[Other]',\n",
        "  'latest_values': 'trafficSource_medium:[cpm,cpc,referral,affiliate,organic]:[Other];device_isMobile:[false,true]:[Other]',\n",
        "  'proportions_values': 'trafficSource_medium:[cpm,cpc,referral,affiliate,organic]:[Other];device_isMobile:[false,true]:[Other]',\n",
        "  'mode_values': 'trafficSource_medium:[cpm,cpc,referral,affiliate,organic]:[Other];device_isMobile:[false,true]:[Other]',\n",
        "}\n",
        "\n",
        "ml_windowing_pipeline.run_prediction_pipeline(scoring_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "320b1041",
      "metadata": {
        "id": "320b1041"
      },
      "source": [
        "## Step 2. Run Batch Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a33fe85b",
      "metadata": {
        "id": "a33fe85b"
      },
      "outputs": [],
      "source": [
        "# Initialize BigQuery client\n",
        "bq_client = bigquery_utils.BigQueryUtils(project_id=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "095cf2af",
      "metadata": {
        "id": "095cf2af"
      },
      "outputs": [],
      "source": [
        "# Configure features input table to be scored, output table and model name\n",
        "FEATURES_TABLE_NAME = f'features_{RUN_ID}'\n",
        "PREDICTION_TABLE_NAME = f'scored_{RUN_ID}'\n",
        "MODEL_NAME = 'test_model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5efd43cb",
      "metadata": {
        "id": "5efd43cb"
      },
      "outputs": [],
      "source": [
        "# Extract pretrained model features. This helps to verify which features were\n",
        "# used to train the propensity model.\n",
        "sql = f\"\"\"\n",
        "  SELECT\n",
        "    input\n",
        "  FROM ML.FEATURE_INFO(MODEL `{PROJECT_ID}.{DATASET_NAME}.{MODEL_NAME}`);\n",
        "\"\"\"\n",
        "expected_features = bq_client.run_query(sql).to_dataframe()\n",
        "expected_features = expected_features['input'].tolist()\n",
        "print(f'Model expects following input features: \\n {expected_features}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c9880f3",
      "metadata": {
        "id": "8c9880f3"
      },
      "outputs": [],
      "source": [
        "# These params are passed to PropensityModel object to run batch prediction.\n",
        "# If binary predictions are required, add `threshold` param to the scoring\n",
        "# params. Example: {'threshold': 0.5}.\n",
        "scoring_params = {\n",
        "  'model_path': f'{PROJECT_ID}.{DATASET_NAME}.{MODEL_NAME}',\n",
        "  'features_table_path': f'{PROJECT_ID}.{DATASET_NAME}.{FEATURES_TABLE_NAME}',\n",
        "  'output_table_path': f'{PROJECT_ID}.{DATASET_NAME}.{PREDICTION_TABLE_NAME}',\n",
        "  'feature_columns': expected_features\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99791a39",
      "metadata": {
        "id": "99791a39"
      },
      "outputs": [],
      "source": [
        "# Execute batch prediction job\n",
        "propensity_model = model.PropensityModel(bq_client=bq_client,\n",
        "                                         params=scoring_params)\n",
        "propensity_model.predict(params=scoring_params, verbose=False, overwrite_table=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "7.batch_scoring.ipynb",
      "provenance": []
    },
    "environment": {
      "name": "common-cpu.m71",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m71"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
