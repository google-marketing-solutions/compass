{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxntJHpGGbWJ"
      },
      "outputs": [],
      "source": [
        "# Copyright 2021 Google LLC.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL72VhdvwRlN"
      },
      "source": [
        "## Design Goals\n",
        "1. Prepare datasets for ML workflow.\n",
        "1. Decide on and execute balancing and splitting strategies.\n",
        "1. Create separate datasets for TRAIN/VALID/TEST.\n",
        "\n",
        "## Requirements\n",
        "1. Using ML Windowing Pipeline to create instances and features tables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K-akTYXwRlN"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nj1IEIOAs9O"
      },
      "outputs": [],
      "source": [
        "# !pip install gps_building_blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8YqU8DxwRlO"
      },
      "outputs": [],
      "source": [
        "import google.auth\n",
        "from google.cloud import bigquery\n",
        "from gps_building_blocks.cloud.utils import bigquery as bigquery_utils\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFqIBFNtwRlQ"
      },
      "source": [
        "### Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZu8bQGKwRlQ"
      },
      "outputs": [],
      "source": [
        "# Prints all the outputs from cell (instead of using display each time).\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "# Plotting configuration.\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"figure.figsize\"] = [20, 20]\n",
        "\n",
        "# Formatting to show full numbers and suppress scientific notation.\n",
        "pd.set_option('display.float_format', lambda x: '%.10f' % x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dWnMP1jwRlS"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed-O0oJhwRlS"
      },
      "outputs": [],
      "source": [
        "# Project we are working in.\n",
        "PROJECT_ID = 'project-id'\n",
        "\n",
        "# Name of the BigQuery dataset with mlwp tables.\n",
        "DATASET_SOURCE = \"dataset\"\n",
        "# Name of the destinaton dataset where we will add ml datasets.\n",
        "DATASET_DESTINATION = \"experiment\"\n",
        "\n",
        "# Initial mwlp tables.\n",
        "TABLE_INSTANCES = 'instances_01'\n",
        "TABLE_FEATURES = 'features_01'\n",
        "\n",
        "# ML datasets\n",
        "# These 3 tables will be created in dataset destination.\n",
        "TABLE_DS_SPLIT = 'ds_split'\n",
        "TABLE_DS_TRAINING_BALANCED = 'ds_training_balanced'\n",
        "TABLE_DS_TEST_TABLE ='ds_test_table'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIbKMokdwRlP"
      },
      "outputs": [],
      "source": [
        "# Initialize BigQuery client.\n",
        "bq_client = bigquery_utils.BigQueryUtils(project_id=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-uXsf90wRlS"
      },
      "source": [
        "## Check underlying data.\n",
        "\n",
        "- check imbalance\n",
        "- verify date to use as a cut off for the ml datasets based on positive rate trends\n",
        "- look at the difference in instances and features dataset in terms of total records and labels\n",
        "- determine right splitting strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woS3zhyrwRlT"
      },
      "source": [
        "### Check Instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmNl0g3SAs9Q"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "SELECT\n",
        "  EXTRACT(DATE\n",
        "  FROM\n",
        "    (snapshot_ts)) AS effective_date,\n",
        "  COUNT(*) AS total_records,\n",
        "  COUNTIF(label=TRUE) AS count_positive,\n",
        "  COUNTIF(label=FALSE) AS count_negative,\n",
        "  SAFE_DIVIDE(COUNTIF(label=TRUE),COUNTIF(label=FALSE)) AS ratio_positive_to_negative\n",
        "FROM\n",
        "  `{DATASET_SOURCE}.{TABLE_INSTANCES}`\n",
        "GROUP BY\n",
        "  1\n",
        "ORDER BY\n",
        "  1 desc;\n",
        "\"\"\"\n",
        "print (sql)\n",
        "df_raw = bq_client.run_query(sql).to_dataframe()\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbtK21kFwRlU"
      },
      "outputs": [],
      "source": [
        "df_instances_check = df_raw.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEzuLDMFwRlU"
      },
      "outputs": [],
      "source": [
        "fig = px.line(\n",
        "    df_instances_check, x=\"effective_date\",\n",
        "    y=\"ratio_positive_to_negative\",\n",
        "    hover_name=\"count_positive\",\n",
        "    title='Positive instances',\n",
        "    height=800)\n",
        "fig.show()\n",
        "df_instances_check.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiI4K1NuwRlV"
      },
      "source": [
        "### Check Features dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWQooJIawRlV"
      },
      "outputs": [],
      "source": [
        "# Check list of columns to investigate what features are available.\n",
        "sql = f\"\"\"\n",
        "SELECT\n",
        " *\n",
        "FROM\n",
        "  `{DATASET_SOURCE}.{TABLE_FEATURES}`\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "print (sql)\n",
        "df_raw = bq_client.run_query(sql).to_dataframe()\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3GcO6qjwRlV"
      },
      "outputs": [],
      "source": [
        "df_raw.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu-NkJAiwRlW"
      },
      "source": [
        "### Proportion of positive instances in features table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o1aG6X7wRlW"
      },
      "outputs": [],
      "source": [
        "# Produce summary of labels (positive/negative).\n",
        "sql = f\"\"\"\n",
        "SELECT\n",
        "  EXTRACT(DATE FROM snapshot_ts) AS effective_date,\n",
        "  COUNT(*) AS total_records,\n",
        "  COUNTIF(label=TRUE) AS count_positive,\n",
        "  COUNTIF(label=FALSE) AS count_negative,\n",
        "  SAFE_DIVIDE(COUNTIF(label=TRUE),\n",
        "  COUNTIF(label=FALSE)) AS ratio_positive_to_negative\n",
        "FROM\n",
        "  `{DATASET_SOURCE}.{TABLE_FEATURES}`\n",
        "GROUP BY\n",
        "  1\n",
        "ORDER BY\n",
        "  1 DESC;\n",
        "\"\"\"\n",
        "print (sql)\n",
        "df_raw = bq_client.run_query(sql).to_dataframe()\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2nhE4LGwRlW"
      },
      "outputs": [],
      "source": [
        "df_features_check = df_raw.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sxXK-xBwRlX"
      },
      "outputs": [],
      "source": [
        "fig = px.line(df_features_check,\n",
        "              x='effective_date',\n",
        "              y='ratio_positive_to_negative',\n",
        "              hover_name='count_positive',\n",
        "              title='Positive instances',\n",
        "              height=800)\n",
        "fig.show()\n",
        "df_features_check.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARk-oHrJwRlX"
      },
      "source": [
        "### Comparison of instances and features tables.\n",
        " \n",
        "This allows us to assess the impact of applying a look back window when creating features. Instance table is using all previous sessions whereas features will use sessions inside the prediction window (for example 90 days). So that will reduce the number of users being considered and matched with the label. By applying a look back window we are potentially reducing the number of possible positive instances, at the same time we would expect the ratio of positive instances to number records to be better for more recent data, so the further in the past we go in general the smaller incremental number of positive instances we can get.\n",
        "\n",
        "Here are few selected fields that can help with understanding the impact of selected look back period:\n",
        "\n",
        "- `total_records_diff` - positive instances that are not in the features table\n",
        "- `other_positive_instances_pct` - what percentage of positive instances we are not including due to selection of the look-back window\n",
        "- `features_by_instances_positive_ratio` - how many times larger is the - positive ratio in features than the instances table\n",
        "- `features_by_instances_total_records` - how many times smaller is the number of records in feature table than instances table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYkb0l6SwRlY"
      },
      "outputs": [],
      "source": [
        "df_combined = df_instances_check.set_index('effective_date').join(\n",
        "    df_features_check.set_index('effective_date'),\n",
        "    how='outer',\n",
        "    rsuffix='_features')\n",
        "df_combined['total_records_diff'] = df_combined['total_records'] - df_combined[\n",
        "    'total_records_features']\n",
        "df_combined['count_positive_diff'] = df_combined[\n",
        "    'count_positive'] - df_combined['count_positive_features']\n",
        "df_combined['ratio_positive_to_negative_diff'] = df_combined[\n",
        "    'ratio_positive_to_negative'] - df_combined[\n",
        "        'ratio_positive_to_negative_features']\n",
        "df_combined.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYqnNzaiwRlY"
      },
      "outputs": [],
      "source": [
        "cols = ['total_records',\n",
        "        'total_records_features',\n",
        "        'count_positive',\n",
        "        'count_positive_features',\n",
        "        'total_records_diff',\n",
        "        'count_positive_diff']\n",
        "\n",
        "df_summary = pd.DataFrame(df_combined[cols].sum())\n",
        "df_summary = df_summary.rename(columns={0: 'value'}).T\n",
        "df_summary['positive_ratio'] = df_summary['count_positive'] / df_summary[\n",
        "    'total_records']\n",
        "df_summary['positive_ratio_features'] = df_summary[\n",
        "    'count_positive_features'] / df_summary['total_records_features']\n",
        "df_summary['features_by_instances_positive_ratio'] = df_summary[\n",
        "    'positive_ratio_features'] / df_summary['positive_ratio']\n",
        "df_summary['features_by_instances_total_records'] = df_summary[\n",
        "    'total_records_features'] / df_summary['total_records']\n",
        "df_summary['other_positive_instances_pct'] = df_summary[\n",
        "    'count_positive_diff'] / df_summary['count_positive'] * 100\n",
        "df_summary.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lq2aA5g6mVI"
      },
      "source": [
        "## Create dataset with split.\n",
        "\n",
        "There are multiple ways to split the dataset.\n",
        "\n",
        "- random sample of rows\n",
        "- deterministic random sample of rows (based on hashid)\n",
        "- temporal split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1H4Pb0FwRlZ"
      },
      "source": [
        "### Create dataset with split on effective dates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnCfbYsXwRla"
      },
      "source": [
        "#### Get recent effective dates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cWZ659EwRla"
      },
      "outputs": [],
      "source": [
        "# Get last effective dates.\n",
        "n_last_dates = 3\n",
        "recent_dates = df_features_check['effective_date'].sort_values(\n",
        "    ascending=False).head(n_last_dates).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV7rkM6JwRla"
      },
      "outputs": [],
      "source": [
        "# Keep this if you want to use data driven values for last dates in the dataset.\n",
        "test_dates = [str(x) for x in recent_dates]\n",
        "\n",
        "# Define dates here if you want to overwrite with curated dates.\n",
        "# It is useful to keep looking at a date that was used when\n",
        "# evaluating original model so we can make sure all performs as expected.\n",
        "# test_dates = ('2021-05-15', '2021-05-09')\n",
        "if len(test_dates) == 1:\n",
        "  test_dates = f\"('{tuple(test_dates)[0]}')\"\n",
        "else:\n",
        "  test_dates = tuple(test_dates)\n",
        "test_dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cgefSttwRla"
      },
      "outputs": [],
      "source": [
        "# Create the dataset if it doesn't exist.\n",
        "# TODO(): Fix the dataset creation with bq_client(utils version).\n",
        "dataset = bqclient.create_dataset(PROJECT_ID + '.' + DATASET_DESTINATION, exists_ok=True)\n",
        "print(f'https://console.cloud.google.com/bigquery?project={PROJECT_ID}\u0026p={PROJECT_ID}\u0026d={DATASET_DESTINATION}\u0026page=dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3DpzF22wRlb"
      },
      "source": [
        "### Create dataset with columns indicating allocation to TRAIN/VALIDATE/TEST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1yDeFH3wRlb"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "# Add additional columns to dataset to indicate which rows are in which part (train/validate/test).\n",
        "# Compliant with automl split conventions.\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_DESTINATION}.{TABLE_DS_SPLIT}` AS (\n",
        "WITH\n",
        "  ds_features_key AS (\n",
        "  SELECT\n",
        "    *,\n",
        "    FARM_FINGERPRINT(user_id) AS key,\n",
        "  FROM\n",
        "    `{PROJECT_ID}.{DATASET_SOURCE}.{TABLE_FEATURES}`)\n",
        "SELECT\n",
        "*,\n",
        "  CASE\n",
        "    WHEN EXTRACT(DATE FROM TIMESTAMP (snapshot_ts)) in {test_dates} THEN 'TEST'\n",
        "    WHEN EXTRACT(DATE FROM TIMESTAMP (snapshot_ts)) not in {test_dates} and MOD(ABS(key), 10) in (0,1,2,3,4,5,6,7) THEN 'TRAIN'\n",
        "    WHEN EXTRACT(DATE FROM TIMESTAMP (snapshot_ts)) not in {test_dates} and MOD(ABS(key), 10) in (8) THEN 'VALIDATE'\n",
        "    WHEN EXTRACT(DATE FROM TIMESTAMP (snapshot_ts)) not in {test_dates} and  MOD(ABS(key), 10) in (9) THEN 'TEST'\n",
        "END as split,\n",
        "FROM\n",
        "  ds_features_key;\n",
        "  )\n",
        "\"\"\"\n",
        "print (sql)\n",
        "df_raw = bq_client.run_query(sql).to_dataframe()\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sSJTG2MwRlb"
      },
      "source": [
        "## Create test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNSzkJDewRlb"
      },
      "outputs": [],
      "source": [
        "TABLE_DS_TEST_TABLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsyQnADTwRlb"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_DESTINATION}.{TABLE_DS_TEST_TABLE}` AS (\n",
        "SELECT * FROM\n",
        "`{PROJECT_ID}.{DATASET_DESTINATION}.{TABLE_DS_SPLIT}`\n",
        "WHERE EXTRACT(DATE FROM TIMESTAMP (snapshot_ts)) in {test_dates}\n",
        ")\n",
        "\"\"\"\n",
        "print (sql)\n",
        "df_raw = bq_client.run_query(sql).to_dataframe()\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYBsqmqIwRlc"
      },
      "source": [
        "## Create balanced Train dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlZH3gBJwRlc"
      },
      "source": [
        "Below SQL script keeps all positive instances and then randomly samples records with negative labels, balance_ratio is a parameter we set to control how many times bigger is the number of negative instances comparing to number of positive instances in the resulting dataset. For example balance_ratio=99 would mean that for every positive instance we are sampling 99 negative instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA5Zb93swRlc"
      },
      "outputs": [],
      "source": [
        "balance_ratio = 99\n",
        "sql = f\"\"\"\n",
        "# Checks imbalance in features by grouping on train/test/validate dataset.\n",
        "# Automatically balances and downsamples dataset and create one for training.\n",
        "CREATE OR REPLACE TABLE\n",
        "  `{PROJECT_ID}.{DATASET_DESTINATION}.{TABLE_DS_TRAINING_BALANCED}` AS (\n",
        "WITH\n",
        "  dataset AS (\n",
        "  SELECT\n",
        "    *\n",
        "  FROM\n",
        "    `{PROJECT_ID}.{DATASET_DESTINATION}.{TABLE_DS_SPLIT}`\n",
        "  WHERE\n",
        "    split='TRAIN' ),\n",
        "  imbalance_stats AS (\n",
        "  SELECT\n",
        "    split,\n",
        "    COUNT(*) AS total_records,\n",
        "    COUNTIF(label=TRUE) AS count_positive,\n",
        "    COUNTIF(label=FALSE) AS count_negative,\n",
        "    FORMAT(\"%.5f\", COUNTIF(label=TRUE)/COUNTIF(label=FALSE)) AS ratio_positive_to_negative\n",
        "  FROM\n",
        "    dataset\n",
        "  GROUP BY\n",
        "    1\n",
        "  ORDER BY\n",
        "    1),\n",
        "  -- Add a random seed to the negative examples.\n",
        "  negatives AS (\n",
        "  SELECT\n",
        "    *,\n",
        "    RAND() AS rand_seed\n",
        "  FROM\n",
        "    dataset\n",
        "  WHERE\n",
        "    label = FALSE),\n",
        "  negative_sampled AS (\n",
        "  SELECT\n",
        "    * EXCEPT (rand_seed)\n",
        "  FROM\n",
        "    negatives\n",
        "  WHERE\n",
        "    -- Here we are sampling the negatives using designed proportion.\n",
        "    rand_seed \u003c= (\n",
        "    SELECT\n",
        "      CAST(ratio_positive_to_negative AS float64)\n",
        "    FROM\n",
        "      imbalance_stats)*{balance_ratio} )\n",
        "  -- Union all together.\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  negative_sampled\n",
        "UNION ALL\n",
        "  -- Add all positive examples.\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  dataset\n",
        "WHERE\n",
        "  label = TRUE AND split='TRAIN'\n",
        "  );\n",
        "\"\"\"\n",
        "print (sql)\n",
        "df_raw = bq_client.run_query(sql).to_dataframe()\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLBnrxtFwRlc"
      },
      "source": [
        "### Check label balance in the new traning balanced dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC9fsl4KwRlc"
      },
      "outputs": [],
      "source": [
        "# Produce summary of labels(positive/negative).\n",
        "sql = f\"\"\"\n",
        "SELECT\n",
        "  snapshot_ts,\n",
        "  COUNT(*) AS total_records,\n",
        "  COUNTIF(label=TRUE) AS count_positive,\n",
        "  COUNTIF(label=FALSE) AS count_negative,\n",
        "  FORMAT(\"%.7f\", SAFE_DIVIDE(COUNTIF(label=TRUE),COUNTIF(label=FALSE))) AS ratio_positive_to_negative,\n",
        "  FORMAT(\"%.7f\", SAFE_DIVIDE(COUNTIF(label=TRUE), COUNT(*))) AS ratio_positive\n",
        "FROM\n",
        "  `{DATASET_DESTINATION}.{TABLE_DS_TRAINING_BALANCED}`\n",
        "GROUP BY\n",
        "  1\n",
        "ORDER BY\n",
        "  1 DESC;\n",
        "\"\"\"\n",
        "\n",
        "print (sql)\n",
        "df_raw = bq_client.run_query(sql).to_dataframe()\n",
        "df_raw.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/dm_python:dm_notebook3",
        "kind": "private"
      },
      "name": "3_ml_data_preprocessing.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/third_party/professional_services/solutions/compass/packages/propensity/3_ml_data_preprocessing.ipynb?workspaceId=szczecinski:dev_compass_ml_preprocessing::citc",
          "timestamp": 1630655505596
        },
        {
          "file_id": "/piper/depot/google3/third_party/professional_services/solutions/compass/packages/propensity/3_ml_data_preprocessing.ipynb?workspaceId=szczecinski:dev_compass_ml_preprocessing::citc",
          "timestamp": 1630591931954
        },
        {
          "file_id": "/piper/depot/google3/third_party/professional_services/solutions/compass/packages/propensity/3_ml_data_preprocessing.ipynb?workspaceId=szczecinski:dev_compass_ml_preprocessing::citc",
          "timestamp": 1630425498904
        },
        {
          "file_id": "1bG5YLs51NoiibKl1CPGybSej756rFdkQ",
          "timestamp": 1629087932840
        }
      ]
    },
    "environment": {
      "name": "common-cpu.m46",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m46"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
