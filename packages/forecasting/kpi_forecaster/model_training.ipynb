{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5UGz4Y5UPxL"
      },
      "source": [
        "Copyright 2021 Google LLC..\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "     http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ishhDI6zUPxO"
      },
      "source": [
        "# About\n",
        "\n",
        "This notebook builds an AutoML model for predicting the future value of a business KPI such as sales, store visits, or leads. It executes the following steps:\n",
        "\n",
        "- generates an ML dataset (instances, features and label on a daily basis)\n",
        "- generates plots for Exploratory Data Analysis (EDA)\n",
        "- separates development and out of time test data partitions\n",
        "- generates correlation plots between features and the label\n",
        "- trains an AutoML model using the development set\n",
        "- validates the model predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWF5VYavUPxP"
      },
      "source": [
        "## Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwohtdXfUPxP"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import pandas as pd\n",
        "import forecaster_util\n",
        "from utils import template_util\n",
        "from google.cloud import bigquery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRPcNfDmUPxQ"
      },
      "source": [
        "## Input parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xseMYbQLUPxQ"
      },
      "outputs": [],
      "source": [
        "# Date of this training run (usually today). All output BigQuery tables,\n",
        "# including the features table and the model, will have this date suffix.\n",
        "# NB: run_date can be overridden with any date in the format: 'YYYYMMDD'.\n",
        "run_date = datetime.datetime.today().strftime('%Y%m%d')\n",
        "\n",
        "parameters = {\n",
        "    # GCP project.\n",
        "    'project_id': '',\n",
        "    # BigQuery dataset to store the output featues and model. Must be located in\n",
        "    # the US or EU, as required by AutoML.\n",
        "    'dataset_id': '',\n",
        "\n",
        "    # BigQuery SQL query to extract the raw training data. Note there must be\n",
        "    # one column called 'ts' of type TIMESTAMP, and one column for the label (\n",
        "    # i.e. the KPI to forecast). The label column can have any name. The query\n",
        "    # must also extract any numeric (INT64, FLOAT64) columns used in the model.\n",
        "    'data_query': \"\"\"\"\"\",\n",
        "    # Name of the BigQuery column containing the numeric key business objective\n",
        "    # that the model will predict.\n",
        "    'label': '',\n",
        "    # BigQuery column names of numeric features in the data_query that will be\n",
        "    # used to help predict the label.\n",
        "    'numeric_features': [],\n",
        "    # By default, all data in the data_query is used. Specify a start_date or\n",
        "    # end_date below to restrict the date range. Date format: 'YYYY-MM-DD'.\n",
        "    'start_date': '',\n",
        "    'end_date': '',\n",
        "    # Reserve this latest fraction of data for testing. Must be in the range\n",
        "    # (0, 1), non-inclusive.\n",
        "    'oot_test_fraction': 0.1,\n",
        "\n",
        "    # Window size.\n",
        "    'window_size': 'HOUR',  # One of HOUR, DAY, WEEK.\n",
        "\n",
        "    # Make predictions for this many prediction_windows in the future. These\n",
        "    # are default values for each prediction_window_size and can be overriden.\n",
        "    'num_hour_prediction_windows': 72,\n",
        "    'num_day_prediction_windows': 28,\n",
        "    'num_week_prediction_windows': 4,\n",
        "\n",
        "    # List of windows. Numeric features are constructed over historical window\n",
        "    # periods. Each window is specified with a pair (window_start, window_end),\n",
        "    # which corresponds to the range (today - window_start day) to\n",
        "    # (today + window_end days) inclusive\n",
        "    'hour_lookback_windows': [\n",
        "        (1, 1), (2, 2), (3, 3), (4, 4), (24, 24), (2 * 24, 2 * 24),\n",
        "        (7 * 24, 7 * 24), (14 * 24, 14 * 24), (21 * 24, 21 * 24),\n",
        "        (28 * 24, 28 * 24), (7*24, 1), (21*24, 7*24), (35*24, 21*24)],\n",
        "    'day_lookback_windows': [\n",
        "        (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (14, 14),\n",
        "        (21, 21), (28, 28), (7, 1), (21, 8), (49, 22)],\n",
        "    'week_lookback_windows': [\n",
        "        (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (14, 14),\n",
        "        (21, 21), (28, 28), (7, 1), (21, 8), (49, 22)],\n",
        "\n",
        "    # List of BigQuery aggregation functions to apply to the historical windows.\n",
        "    'aggregate_functions': ['SUM', 'AVG'],\n",
        "\n",
        "    # Name of the ouput features table (default: features_YYYYMMDD).\n",
        "    'features_table': f'features_{run_date}',\n",
        "    # Name of the ouput model table (default: model_YYYYMMDD)\n",
        "    'model_table': f'model_{run_date}',\n",
        "    # Development ML dataset table (default: ml_development_table_YYYYMMDD).\n",
        "    'ml_development_table': f'ml_development_data_{run_date}',\n",
        "    # OOT testing ML dataset table (default: ml_oot_testing_table_YYYYMMDD).\n",
        "    'ml_oot_testing_table': f'ml_oot_testing_data_{run_date}',\n",
        "\n",
        "    # SQL template locations.\n",
        "    'create_model_input_data_template':\n",
        "        'templates/create_model_input_data.sql',\n",
        "    'features_template': 'templates/features.sql',\n",
        "    'train_model_template': 'templates/train_model.sql',\n",
        "    'evaluate_model_template': 'templates/evaluate_model.sql',\n",
        "    'prediction_template': 'templates/prediction.sql'\n",
        "}\n",
        "if parameters['window_size'] == 'HOUR':\n",
        "  parameters['micros_per_window'] = 60 * 60 * 1000000\n",
        "  parameters['num_prediction_periods'] = parameters[\n",
        "      'num_hour_prediction_windows']\n",
        "  parameters['lookback_windows'] = parameters['hour_lookback_windows']\n",
        "  parameters['grouping_column_name'] = 'hournum'\n",
        "elif parameters['window_size'] == 'DAY':\n",
        "  parameters['micros_per_window'] = 24 * 60 * 60 * 1000000\n",
        "  parameters['num_prediction_periods'] = parameters[\n",
        "      'num_day_prediction_windows']\n",
        "  parameters['lookback_windows'] = parameters['day_lookback_windows']\n",
        "  parameters['grouping_column_name'] = 'weekday'\n",
        "elif parameters['window_size'] == 'WEEK':\n",
        "  parameters['micros_per_window'] = 7 * 24 * 60 * 60 * 1000000\n",
        "  parameters['num_prediction_periods'] = parameters[\n",
        "      'num_week_prediction_windows']\n",
        "  parameters['lookback_windows'] = parameters['week_lookback_windows']\n",
        "  parameters['grouping_column_name'] = 'weeknum'\n",
        "else:\n",
        "  assert('Error: Unknown window_size', parameters['window_size'])\n",
        "\n",
        "parameters['max_lookback'] = max(\n",
        "    [window_start for (window_start, _) in parameters['lookback_windows']])\n",
        "parameters['training_mode'] = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZoGQa9gUPxW"
      },
      "source": [
        "### Create ML Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxnfFwdFUPxX"
      },
      "outputs": [],
      "source": [
        "# Create a BigQuery client\n",
        "client = bigquery.Client(parameters['project_id'])\n",
        "client.create_dataset(parameters['dataset_id'], exists_ok=True)\n",
        "\n",
        "# Create the features table\n",
        "create_features_table_query = template_util.render_template(\n",
        "    parameters['create_model_input_data_template'], parameters)\n",
        "client.query(create_features_table_query).result();\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA0IPW6WUPxX"
      },
      "source": [
        "### Exploratory Data Analysis (EDA) and ML Data Partition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lesfNzAzUPxY"
      },
      "outputs": [],
      "source": [
        "# Read in data from BigQuery\n",
        "features_table = (\n",
        "    f\"{parameters['project_id']}.{parameters['dataset_id']}.\"\n",
        "    f\"{parameters['features_table']}\")\n",
        "ml_data = client.list_rows(features_table).to_dataframe()\n",
        "ml_data = ml_data.sort_values(['ts', 'prediction_period']).drop_duplicates()\n",
        "\n",
        "# Visualize the label over time\n",
        "label_column = f\"label_{parameters['label']}\"\n",
        "ml_data[ml_data.prediction_period == 0][['ts', label_column]].plot(\n",
        "    x='ts', figsize=(30, 10));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VY2MuCKUUPxY"
      },
      "outputs": [],
      "source": [
        "# Seperate the ML data into Development and Out of time (OOT) test sets based on\n",
        "# selected time periods.\n",
        "\n",
        "development_instances = int(len(ml_data)*(1 - parameters['oot_test_fraction']))\n",
        "\n",
        "development = ml_data[:development_instances]\n",
        "oot_test = ml_data[development_instances:]\n",
        "print(f\"Number of development instances ({development[['ts']].min()[0]} \"\n",
        "      f\"to {development[['ts']].max()[0]}): {development.shape[0]}\")\n",
        "print(f\"Number of OOT testing instances ({oot_test[['ts']].min()[0]} \"\n",
        "      f\"to {oot_test[['ts']].max()[0]}): {oot_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIgA_U8eUPxZ"
      },
      "outputs": [],
      "source": [
        "# If the number of instances in the development dataset is \u003c 1000, add\n",
        "# duplicate instances to make it 1000 as per the requirment of AutoML.\n",
        "if development.shape[0] \u003c 1000:\n",
        "  duplicates = development.sample(1000 - development.shape[0], replace=True)\n",
        "  development = pd.concat([development, duplicates])\n",
        "print('Number of development instances:', development.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhXZ12T2UPxZ"
      },
      "outputs": [],
      "source": [
        "# Visualize the label distribution of the data over time\n",
        "label_column = f\"label_{parameters['label']}\"\n",
        "ml_data[ml_data.prediction_period == 0].plot(\n",
        "    x='ts',\n",
        "    y=label_column,\n",
        "    figsize=(25, 10),\n",
        "    title='All Instances Label Distribution')\n",
        "\n",
        "# Visualize the label distribution of the development dataset over time\n",
        "development[ml_data.prediction_period == 0].plot(\n",
        "    x='ts',\n",
        "    y=label_column,\n",
        "    figsize=(25, 10),\n",
        "    title='Development Instances Label Distribution')\n",
        "\n",
        "# Visualize the label distribution of of OOT Test partition over time\n",
        "oot_test[ml_data.prediction_period == 0].plot(\n",
        "    x='ts',\n",
        "    y=label_column,\n",
        "    figsize=(25, 10),\n",
        "    title='OOT Test Instances Label Distribution');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRoDqy5wUPxZ"
      },
      "outputs": [],
      "source": [
        "# Explore the correlation between the features and label for Development and\n",
        "# OOT Test partions\n",
        "forecaster_util.plot_dev_and_test_feature_correlations_with_label(\n",
        "    development, oot_test, label_column);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJ0IVfCMUPxZ"
      },
      "outputs": [],
      "source": [
        "# Save the ML datasets into BQ tables\n",
        "job_config = bigquery.job.LoadJobConfig()\n",
        "job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
        "client.load_table_from_dataframe(\n",
        "    development,\n",
        "    f\"{parameters['dataset_id']}.{parameters['ml_development_table']}\",\n",
        "    job_config=job_config).result()\n",
        "client.load_table_from_dataframe(\n",
        "    oot_test,\n",
        "    f\"{parameters['dataset_id']}.{parameters['ml_oot_testing_table']}\",\n",
        "    job_config=job_config).result();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQtOCFarUPxa"
      },
      "source": [
        "### Train AutoML Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YonIiRAMUPxa"
      },
      "outputs": [],
      "source": [
        "# Note that this steps takes hours to run.\n",
        "\n",
        "create_model_query = template_util.render_template(\n",
        "    parameters['train_model_template'],\n",
        "    {**parameters, 'input_features_table': parameters['ml_development_table']})\n",
        "print('Running query:', create_model_query)\n",
        "client.query(create_model_query).result()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNCdiOyCUPxa"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYltWz63UPxa"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model based on the testing partition of the development set \n",
        "\n",
        "evaluation_query = template_util.render_template(\n",
        "    parameters['evaluate_model_template'], parameters)\n",
        "for row in list(client.query(evaluation_query).result()):\n",
        "  for (metric, value) in dict(row).items():\n",
        "    print(f'{metric:\u003c25}{value:=10.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEX56vdXUPxb"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model based on the whole development set.\n",
        "predicted_label_column = f'predicted_{label_column}'\n",
        "\n",
        "# Run prediction on the development set.\n",
        "prediction_query = template_util.render_template(\n",
        "    parameters['prediction_template'],\n",
        "    {**parameters, 'input_features_table': parameters['ml_development_table']})\n",
        "dev_pred_data = client.query(prediction_query).to_dataframe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7eNqIX1qNYu"
      },
      "outputs": [],
      "source": [
        "# Plot predictions against labels for the development set.\n",
        "\n",
        "import importlib\n",
        "importlib.reload(forecaster_util)\n",
        "\n",
        "\n",
        "forecaster_util.plot_predictions_against_labels(\n",
        "    dev_pred_data[dev_pred_data.prediction_period == 0],\n",
        "    label_column, predicted_label_column)\n",
        "# Output the mae and mape for each day of the week (Sunday to Saturday). \n",
        "print(forecaster_util.calculate_performance_by_grouping(\n",
        "    dev_pred_data[dev_pred_data.prediction_period == 0],\n",
        "    label_column,\n",
        "    predicted_label_column,\n",
        "    parameters['grouping_column_name']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DrN3XErUPxb"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model based on the OOT testing set\n",
        "\n",
        "# Run prediction on the OOT testing set\n",
        "prediction_query = template_util.render_template(\n",
        "    parameters['prediction_template'],\n",
        "    {**parameters, 'input_features_table': parameters['ml_oot_testing_table']})\n",
        "test_pred_data = client.query(prediction_query).to_dataframe()\n",
        "\n",
        "# Plot predictions against labels for the OOT testing set.\n",
        "forecaster_util.plot_predictions_against_labels(\n",
        "    test_pred_data[test_pred_data.prediction_period == 0],\n",
        "    label_column, predicted_label_column)\n",
        "# Output the mae and mape for each day of the week (Sunday to Saturday).\n",
        "print(forecaster_util.calculate_performance_by_grouping(\n",
        "    test_pred_data[test_pred_data.prediction_period == 0],\n",
        "    label_column,\n",
        "    predicted_label_column,\n",
        "    parameters['grouping_column_name']))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//quality/ranklab/experimental/notebook:rl_colab",
        "kind": "private"
      },
      "name": "ModelTraining.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/third_party/professional_services/solutions/compass/kpi_forecaster/ModelTraining.ipynb?workspaceId=dabraham:forecaster::citc",
          "timestamp": 1626761020006
        },
        {
          "file_id": "/piper/depot/google3/third_party/professional_services/solutions/compass/kpi_forecaster/ModelTraining.ipynb?workspaceId=dabraham:forecaster::citc",
          "timestamp": 1626760984220
        }
      ]
    },
    "environment": {
      "name": "common-cpu.m76",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m76"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
